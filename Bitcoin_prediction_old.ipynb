{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a6a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Data Preparation ---\n",
      "1. Reading raw data from 'btcusd_1-min_data.csv'...\n",
      "2. Creating the 'Next_Day_Open' target variable...\n",
      "   Target created. Dataset has 7153597 rows before filtering.\n",
      "3. Filtering data to keep only rows on or after January 1, 2019...\n",
      "   Filtering complete. Removed 3681479 rows. 3472118 rows remain.\n",
      "4. Saving final processed data to 'final_processed_data.csv'...\n",
      "--- Data Preparation Finished ---\n",
      "\n",
      "Preview of the first 5 rows of 'final_processed_data.csv':\n",
      "            Timestamp     Open     High      Low    Close    Volume  \\\n",
      "3681479  1.546301e+09  3750.62  3752.01  3750.62  3752.01  1.243647   \n",
      "3681480  1.546301e+09  3752.01  3752.01  3752.01  3752.01  0.000000   \n",
      "3681481  1.546301e+09  3752.01  3752.01  3752.01  3752.01  0.000000   \n",
      "3681482  1.546301e+09  3752.01  3752.01  3752.01  3752.01  0.000000   \n",
      "3681483  1.546301e+09  3750.31  3750.31  3750.31  3750.31  0.359107   \n",
      "\n",
      "         Next_Day_Open  \n",
      "3681479        3659.35  \n",
      "3681480        3659.35  \n",
      "3681481        3659.35  \n",
      "3681482        3659.35  \n",
      "3681483        3659.35  \n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. CONFIGURATION AND MODEL DEFINITIONS ---\n",
    "st.set_page_config(layout=\"wide\", page_title=\"Crypto Prediction Engine\")\n",
    "\n",
    "ASSET_CONFIG = {\n",
    "    \"Bitcoin (BTC)\": {\n",
    "        \"model_path\": \"bitcoin_hybrid_pytorch_model.pth\", \"npz_path\": \"bitcoin_hybrid_pytorch_data.npz\", \"raw_data_path\": \"output_10_rows.csv\",\n",
    "        \"time_col\": \"Timestamp\", \"timeframe_type\": \"minute\", \"horizons\": {\n",
    "            \"5 Minutes\": {\"h\": 5, \"t\": \"Target_5m_Pct_Change\"}, \"30 Minutes\": {\"h\": 30, \"t\": \"Target_30m_Pct_Change\"},\n",
    "            \"4 Hours\": {\"h\": 240, \"t\": \"Target_4h_Pct_Change\"}, \"24 Hours\": {\"h\": 1440, \"t\": \"Target_24h_Pct_Change\"},}},\n",
    "    \"Ethereum (ETH)\": {\n",
    "        \"model_path\": \"ethereum_hybrid_pytorch_model.pth\", \"npz_path\": \"ethereum_hybrid_pytorch_data.npz\", \"raw_data_path\": \"ETH_1min.csv\",\n",
    "        \"time_col\": \"Unix Timestamp\", \"timeframe_type\": \"minute\", \"horizons\": {\n",
    "            \"5 Minutes\": {\"h\": 5, \"t\": \"Target_5m_Pct_Change\"}, \"30 Minutes\": {\"h\": 30, \"t\": \"Target_30m_Pct_Change\"},\n",
    "            \"4 Hours\": {\"h\": 240, \"t\": \"Target_4h_Pct_Change\"}, \"24 Hours\": {\"h\": 1440, \"t\": \"Target_24h_Pct_Change\"},}},\n",
    "    \"XPR\": {\n",
    "        \"model_path\": \"xpr_hybrid_pytorch_model.pth\", \"npz_path\": \"xpr_hybrid_pytorch_data.npz\", \"raw_data_path\": \"XPR_Daily.csv\",\n",
    "        \"time_col\": \"Open time\", \"timeframe_type\": \"minute\", \"horizons\": {\n",
    "            \"5 Minutes\": {\"h\": 5, \"t\": \"Target_5m_Pct_Change\"}, \"30 Minutes\": {\"h\": 30, \"t\": \"Target_30m_Pct_Change\"},\n",
    "            \"4 Hours\": {\"h\": 240, \"t\": \"Target_4h_Pct_Change\"}, \"24 Hours\": {\"h\": 1440, \"t\": \"Target_24h_Pct_Change\"},}},\n",
    "    \"Solana (SOL)\": {\n",
    "        \"model_path\": \"solana_hybrid_pytorch_model.pth\", \"npz_path\": \"solana_hybrid_pytorch_data.npz\", \"raw_data_path\": \"Solana_daily.csv\",\n",
    "        \"time_col\": \"time\", \"timeframe_type\": \"day\", \"horizons\": {\n",
    "            \"1 Day\": {\"h\": 1, \"t\": \"Target_1_Day_Pct_Change\"}, \"7 Days\": {\"h\": 7, \"t\": \"Target_7_Day_Pct_Change\"},\n",
    "            \"30 Days\": {\"h\": 30, \"t\": \"Target_30_Day_Pct_Change\"}, \"90 Days\": {\"h\": 90, \"t\": \"Target_90_Day_Pct_Change\"},}},\n",
    "    \"Dogecoin (DOGE)\": {\n",
    "        \"model_path\": \"doge_hybrid_pytorch_model.pth\", \"npz_path\": \"doge_hybrid_pytorch_data.npz\", \"raw_data_path\": \"DOGE-USD.csv\",\n",
    "        \"time_col\": \"Date\", \"timeframe_type\": \"day\", \"horizons\": {\n",
    "            \"1 Day\": {\"h\": 1, \"t\": \"Target_1_Day_Pct_Change\"}, \"7 Days\": {\"h\": 7, \"t\": \"Target_7_Day_Pct_Change\"},\n",
    "            \"30 Days\": {\"h\": 30, \"t\": \"Target_30_Day_Pct_Change\"}, \"90 Days\": {\"h\": 90, \"t\": \"Target_90_Day_Pct_Change\"},}}\n",
    "}\n",
    "\n",
    "class PyTorchHybridLSTM(nn.Module):\n",
    "    def __init__(self, i, h, n): super(PyTorchHybridLSTM, self).__init__(); self.lstm1=nn.LSTM(i,h,batch_first=True); self.dropout1=nn.Dropout(0.2); self.lstm2=nn.LSTM(h,h,batch_first=True); self.dropout2=nn.Dropout(0.2); self.fc1=nn.Linear(h,25); self.relu=nn.ReLU(); self.fc2=nn.Linear(25,n)\n",
    "    def forward(self, x): o,_=self.lstm1(x); o=self.dropout1(o); o,_=self.lstm2(o); o=self.dropout2(o); o=o[:,-1,:]; o=self.fc1(o); o=self.relu(o); o=self.fc2(o); return o\n",
    "\n",
    "# --- 2. BACKTESTING ENGINE & HELPERS ---\n",
    "@st.cache_resource\n",
    "def load_model(asset_name):\n",
    "    config = ASSET_CONFIG[asset_name]\n",
    "    with np.load(config['npz_path'], allow_pickle=True) as data: X_test, target_cols = data['X_test'], data['target_cols']\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = PyTorchHybridLSTM(X_test.shape[2], 40, len(target_cols)).to(device)\n",
    "    model.load_state_dict(torch.load(config['model_path'], map_location=torch.device(device)))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "@st.cache_data\n",
    "def get_predictions(_model, asset_name):\n",
    "    config = ASSET_CONFIG[asset_name]\n",
    "    with np.load(config['npz_path'], allow_pickle=True) as data: X_test, target_cols = data['X_test'], data['target_cols']\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    test_loader = DataLoader(TensorDataset(torch.from_numpy(X_test.astype(np.float32))), batch_size=512)\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for b in test_loader:\n",
    "            p = _model(b[0].to(device))\n",
    "            all_preds.append(p.cpu().numpy())\n",
    "    return np.concatenate(all_preds, axis=0), target_cols\n",
    "\n",
    "def run_backtest(asset_name, predictions, target_cols, strategy_config):\n",
    "    config = ASSET_CONFIG[asset_name]\n",
    "    raw_df = pd.read_csv(config['raw_data_path'])\n",
    "    if raw_df[config['time_col']].dtype == 'object': raw_df['Timestamp'] = pd.to_datetime(raw_df[config['time_col']])\n",
    "    elif raw_df[config['time_col']].iloc[0] > 10**12: raw_df['Timestamp'] = pd.to_datetime(raw_df[config['time_col']] / 1000, unit='s')\n",
    "    else: raw_df['Timestamp'] = pd.to_datetime(raw_df[config['time_col']], unit='s')\n",
    "    raw_df.sort_values('Timestamp', inplace=True); raw_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    with np.load(config['npz_path'], allow_pickle=True) as data: X_test = data['X_test']\n",
    "    required_len = len(X_test) + strategy_config['holding_period']\n",
    "    test_prices_df = raw_df.tail(required_len).copy().reset_index(drop=True)\n",
    "    \n",
    "    target_col_index = np.where(target_cols == strategy_config['prediction_target'])[0][0]\n",
    "    final_predictions = predictions[:, target_col_index]\n",
    "    trades = []\n",
    "    if strategy_config['type'] == 'Long-Only':\n",
    "        for i in range(len(final_predictions)):\n",
    "            if i + strategy_config['holding_period'] >= len(test_prices_df): break\n",
    "            if final_predictions[i] > strategy_config['trade_threshold']:\n",
    "                entry = test_prices_df['Close'].iloc[i]; exit_price = test_prices_df['Close'].iloc[i + strategy_config['holding_period']]\n",
    "                trades.append({\"return_pct\": ((exit_price - entry) / entry) * 100})\n",
    "    elif strategy_config['type'] == 'Long/Short':\n",
    "        for i in range(len(final_predictions)):\n",
    "            if i + strategy_config['holding_period'] >= len(test_prices_df): break\n",
    "            prediction = final_predictions[i]; entry_price = test_prices_df['Close'].iloc[i]; exit_price = test_prices_df['Close'].iloc[i + strategy_config['holding_period']]\n",
    "            if prediction > strategy_config['trade_threshold']: trades.append({\"return_pct\": ((exit_price - entry_price) / entry_price) * 100})\n",
    "            elif prediction < -strategy_config['trade_threshold']: trades.append({\"return_pct\": ((entry_price - exit_price) / entry_price) * 100})\n",
    "    \n",
    "    if not trades: return None, None, None, None\n",
    "        \n",
    "    trades_df = pd.DataFrame(trades)\n",
    "    total_trades = len(trades_df); win_df = trades_df[trades_df['return_pct'] > 0]; win_rate = len(win_df) / total_trades * 100 if total_trades > 0 else 0\n",
    "    initial_capital = 10000; returns_series = trades_df['return_pct'] / 100; pnl_series = returns_series * initial_capital\n",
    "    equity_curve = pnl_series.cumsum() + initial_capital; final_capital = equity_curve.iloc[-1]; strategy_total_return = (final_capital - initial_capital) / initial_capital * 100\n",
    "    days_in_test = (test_prices_df['Timestamp'].iloc[-1] - test_prices_df['Timestamp'].iloc[0]).days if not test_prices_df.empty else 1\n",
    "    if returns_series.std() != 0 and days_in_test > 0 and total_trades > 0:\n",
    "        sharpe_ratio = returns_series.mean() / returns_series.std()\n",
    "        if config['timeframe_type'] == 'minute': ann_factor = np.sqrt(365*24*60 / (days_in_test*24*60/total_trades)) if (days_in_test*24*60/total_trades) > 0 else 1\n",
    "        else: ann_factor = np.sqrt(365 / (days_in_test/total_trades)) if (days_in_test/total_trades) > 0 else 1\n",
    "        annualized_sharpe = sharpe_ratio * ann_factor\n",
    "    else: annualized_sharpe = 0\n",
    "    peak = equity_curve.expanding(min_periods=1).max(); drawdown = (equity_curve - peak) / peak; max_dd = drawdown.min() * -100 if not drawdown.empty else 0\n",
    "    years_in_test = days_in_test/365.25 if days_in_test > 0 else 1; ann_return = ((final_capital/initial_capital)**(1/years_in_test)-1)*100 if years_in_test > 0 else strategy_total_return\n",
    "    calmar = ann_return/max_dd if max_dd > 0 else 0\n",
    "    buy_hold = (test_prices_df['Close'].iloc[-1] - test_prices_df['Close'].iloc[0]) / test_prices_df['Close'].iloc[0] * 100\n",
    "    results = {\"Strategy Total Return (%)\": strategy_total_return, \"Buy & Hold Return (%)\": buy_hold, \"Annualized Sharpe Ratio\": annualized_sharpe, \"Calmar Ratio\": calmar, \"Max Drawdown (%)\": max_dd, \"Win Rate (%)\": win_rate, \"Total Trades\": total_trades}\n",
    "    return results, equity_curve, peak, drawdown\n",
    "\n",
    "# --- 3. STREAMLIT UI AND APPLICATION LOGIC ---\n",
    "\n",
    "def render_landing_page():\n",
    "    st.title(\"Welcome to the Crypto Price Prediction Engine\")\n",
    "    st.subheader(\"A Dashboard for Backtesting ML-Driven Trading Strategies\")\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\"\"\"This application is the culmination of a comprehensive project to build and validate a predictive modeling pipeline for cryptocurrencies. Here, you can use our best model—the **Hybrid LSTM**—to simulate trading strategies across multiple assets and time horizons.\"\"\")\n",
    "    st.info(\"**Disclaimer:** This is a research tool for educational and analytical purposes only. The results are based on historical data and do not constitute financial advice. Past performance is not indicative of future results.\")\n",
    "    st.header(\"How to Use This Dashboard\")\n",
    "    st.markdown(\"\"\"\n",
    "    1.  **Navigate to the Strategy Dashboard:** Use the sidebar on the left.\n",
    "    2.  **Select an Asset, Time Horizon, and Strategy Type.**\n",
    "    3.  **Adjust the Confidence Threshold:** The slider controls the strategy's sensitivity.\n",
    "    4.  **Run the Backtest:** Click the button to run the simulation. The results will remain on the page until you run a new backtest.\n",
    "    \"\"\")\n",
    "    def go_to_dashboard():\n",
    "        st.session_state.page = \"Strategy Dashboard\"\n",
    "    st.markdown(\"---\")\n",
    "    _, col2 = st.columns([4, 1]); col2.button(\"Go to Dashboard →\", type=\"primary\", on_click=go_to_dashboard)\n",
    "\n",
    "def render_backtester_page():\n",
    "    st.title(\"Strategy Dashboard\")\n",
    "    st.sidebar.header(\"Strategy Configuration\")\n",
    "    selected_asset = st.sidebar.selectbox(\"1. Select Asset\", list(ASSET_CONFIG.keys()), key=\"asset_selector\")\n",
    "    asset_config = ASSET_CONFIG[selected_asset]\n",
    "    selected_horizon = st.sidebar.selectbox(\"2. Select Time Horizon\", list(asset_config[\"horizons\"].keys()), key=\"horizon_selector\")\n",
    "    selected_strategy_type = st.sidebar.radio(\"3. Select Strategy Type\", [\"Long-Only\", \"Long/Short\"], key=\"type_selector\")\n",
    "    base_threshold = st.sidebar.slider(\"4. Select Base Threshold (%)\", 0.05, 2.5, 0.5, 0.05, key=\"thresh_slider\")\n",
    "    \n",
    "    if st.sidebar.button(\"Run Backtest\", key=\"run_button\"):\n",
    "        with st.spinner(f\"Loading model and data for {selected_asset}...\"):\n",
    "            model = load_model(selected_asset)\n",
    "            predictions, target_cols = get_predictions(model, selected_asset)\n",
    "        horizon_props = asset_config[\"horizons\"][selected_horizon]\n",
    "        if asset_config['timeframe_type'] == 'minute': scaled_threshold = base_threshold * (horizon_props[\"h\"] / 1440.0)\n",
    "        else: scaled_threshold = base_threshold * horizon_props[\"h\"]\n",
    "        strategy_config = {\"type\": selected_strategy_type, \"trade_threshold\": scaled_threshold, \"holding_period\": horizon_props[\"h\"], \"prediction_target\": horizon_props[\"t\"]}\n",
    "        with st.spinner(f\"Running backtest...\"):\n",
    "            backtest_results_tuple = run_backtest(selected_asset, predictions, target_cols, strategy_config)\n",
    "        st.session_state['last_run_results'] = backtest_results_tuple\n",
    "        st.session_state['last_run_params'] = {\"asset\": selected_asset, \"horizon\": selected_horizon, \"strategy_type\": selected_strategy_type, \"scaled_threshold\": scaled_threshold, \"base_threshold\": base_threshold}\n",
    "\n",
    "    if 'last_run_results' in st.session_state:\n",
    "        params = st.session_state['last_run_params']; results_data = st.session_state['last_run_results']\n",
    "        st.header(f\"Backtest Results: {params['asset']} - {params['horizon']}\")\n",
    "        st.markdown(f\"**Strategy:** `{params['strategy_type']}` with a scaled threshold of **`{params['scaled_threshold']:.4f}%`** (base `{params['base_threshold']}%`)\")\n",
    "        \n",
    "        # --- THIS IS THE CORRECTED LOGIC ---\n",
    "        # Unpack the tuple first, then check if the first element is valid\n",
    "        results, equity_curve, peak, drawdown = results_data\n",
    "        if results is not None:\n",
    "            col1, col2, col3, col4 = st.columns(4)\n",
    "            col1.metric(\"Strategy Total Return\", f\"{results['Strategy Total Return (%)']:.2f}%\"); col2.metric(\"Buy & Hold Return\", f\"{results['Buy & Hold Return (%)']:.2f}%\")\n",
    "            col3.metric(\"Annualized Sharpe Ratio\", f\"{results['Annualized Sharpe Ratio']:.2f}\"); col4.metric(\"Win Rate\", f\"{results['Win Rate (%)']:.2f}%\")\n",
    "            st.subheader(\"Performance Metrics\")\n",
    "            results_df = pd.DataFrame([results])\n",
    "            st.dataframe(results_df.style.format(\"{:.2f}\").set_properties(**{'text-align': 'center'}), use_container_width=True)\n",
    "            st.subheader(\"Equity Curve & Drawdowns\")\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            ax.plot(equity_curve.index, equity_curve, label='Strategy Equity Curve', color='royalblue', lw=2); ax.plot(peak.index, peak, label='Running Peak', color='limegreen', ls='--', alpha=0.7); ax.fill_between(drawdown.index, equity_curve, peak, where=equity_curve<peak, color='red', alpha=0.3, label='Drawdown')\n",
    "            ax.set_title(f\"Equity Curve for {params['asset']} Strategy\", fontsize=16); ax.set_xlabel('Trade Number'); ax.set_ylabel('Portfolio Value ($)'); ax.legend(loc='upper left'); ax.grid(True)\n",
    "            st.pyplot(fig)\n",
    "        else:\n",
    "            st.warning(\"No trades were triggered for this configuration. This typically means the model's predictions did not cross the required scaled threshold. Try lowering the 'Base Threshold' slider or selecting a different time horizon.\")\n",
    "\n",
    "def render_details_page():\n",
    "    st.title(\"Project Report: From Flawed Models to a Robust Pipeline\")\n",
    "    st.markdown(\"---\"); st.header(\"Phase 1: The Development Journey - A Case Study on Bitcoin\")\n",
    "    st.markdown(\"\"\"Our project began with a single goal: predict the price of Bitcoin. This initial focus served as our R&D phase, where we encountered and solved fundamental challenges that shaped our final, successful methodology.\"\"\")\n",
    "    with st.expander(\"Attempt 1: The Data Leakage Pitfall\"):\n",
    "        st.markdown(\"\"\"- **Goal:** Predict the next day's absolute opening price.\n",
    "                       - **Problem:** The results were astonishingly accurate (99%+ R²). This is a classic sign of **data leakage**. The model was \"cheating\" by using the price at 11:59 PM to \"predict\" the price moments later at 12:00 AM.\n",
    "                       - **Learning:** A model must have a significant time gap between its last piece of information and the event it is predicting.\"\"\")\n",
    "    with st.expander(\"Attempt 2: The Persistence Trap\"):\n",
    "        st.markdown(\"\"\"- **Goal:** Predict the absolute price 24 hours in the future.\n",
    "                       - **Problem:** A simple model won easily by learning the trivial \"persistence\" rule: `Future_Price ≈ Current_Price`. This model provides no real intelligence about market dynamics.\n",
    "                       - **Learning:** Predicting absolute price levels is a flawed objective. We must predict **change** and **movement**.\"\"\")\n",
    "    st.success(\"#### The Breakthrough: Stationarity\")\n",
    "    st.markdown(\"\"\"These initial failures led to the most critical strategic shift of the project. We changed the prediction target from an absolute price to the **future percentage change**. This forced our models to learn the complex relationships between indicators that precede market movement.\"\"\")\n",
    "    st.markdown(\"---\"); st.header(\"Phase 2: Architecture Selection - Standard vs. Hybrid LSTM\")\n",
    "    st.markdown(\"\"\"With a valid problem definition, we moved to more powerful sequence-based models (LSTMs). We tested two primary architectures on our Bitcoin data.\"\"\")\n",
    "    col1, col2 = st.columns(2)\n",
    "    with col1:\n",
    "        st.subheader(\"Standard LSTM\"); st.markdown(\"Given only a sequence of raw OHLCV data.\"); st.code(\"MAE for 24h: 1.70%\")\n",
    "    with col2:\n",
    "        st.subheader(\"Hybrid LSTM\"); st.markdown(\"Given a richer sequence of raw OHLCV data **and** pre-calculated technical indicators (RSI, etc.).\"); st.code(\"MAE for 24h: 1.65%\")\n",
    "    st.markdown(\"- **Result:** For Bitcoin, the **Hybrid LSTM was demonstrably more accurate**. The engineered features provided valuable 'hints' that helped the model overcome the high noise in financial data.\\n- **Our Champion:** Based on this, we selected the **Hybrid LSTM** as our final, most powerful architecture to apply to all assets, which is what powers this dashboard.\")\n",
    "    st.markdown(\"---\"); st.header(\"Phase 3: Creating a Reusable, Multi-Asset Pipeline\")\n",
    "    st.markdown(\"\"\"The final stage was to prove the robustness of our methodology. The entire pipeline was successfully applied to five different assets across two different timeframes (minute and daily).\"\"\")\n",
    "    st.markdown(\"---\"); st.header(\"Project Assets & Notebooks\")\n",
    "    \n",
    "    # --- NEW: NOTEBOOK SECTION ---\n",
    "    notebook_files = [\n",
    "        {\"label\": \"Bitcoin (Initial LightGBM - Failed Models)\", \"filename\": \"Bitcoin_prediction_old.ipynb\"},\n",
    "        {\"label\": \"Bitcoin (Final Hybrid LSTM)\", \"filename\": \"Bitcoin_pred.ipynb\"},\n",
    "        {\"label\": \"Ethereum (Hybrid LSTM)\", \"filename\": \"Ethereum_Pred.ipynb\"},\n",
    "        {\"label\": \"XPR (Hybrid LSTM)\", \"filename\": \"XPR_Pred.ipynb\"},\n",
    "        {\"label\": \"Solana (Hybrid LSTM)\", \"filename\": \"Solana_pred.ipynb\"},\n",
    "        {\"label\": \"Dogecoin (Hybrid LSTM)\", \"filename\": \"Doge_Pred.ipynb\"},\n",
    "    ]\n",
    "    st.subheader(\"Analysis Notebooks (.ipynb)\")\n",
    "    for item in notebook_files:\n",
    "        try:\n",
    "            with open(item[\"filename\"], \"rb\") as fp:\n",
    "                st.download_button(label=f\"Download {item['label']}\", data=fp, file_name=item[\"filename\"], mime=\"application/x-ipynb+json\", key=f\"nb_{item['filename']}\")\n",
    "        except FileNotFoundError:\n",
    "            st.error(f\"File not found: '{item['filename']}'\")\n",
    "\n",
    "    d_col1, d_col2 = st.columns(2)\n",
    "    with d_col1:\n",
    "        st.subheader(\"Trained Models (.pth)\")\n",
    "        for asset in ASSET_CONFIG:\n",
    "            model_file = ASSET_CONFIG[asset]['model_path']\n",
    "            try:\n",
    "                with open(model_file, \"rb\") as fp: st.download_button(label=f\"Download {asset} Model\", data=fp, file_name=model_file, mime=\"application/octet-stream\", key=f\"model_{asset}\")\n",
    "            except FileNotFoundError: st.error(f\"File '{model_file}' not found.\")\n",
    "    with d_col2:\n",
    "        st.subheader(\"Backtest Summaries (.csv)\")\n",
    "        for asset_key in [\"bitcoin\", \"ethereum\", \"xpr\", \"solana\", \"dogecoin\"]:\n",
    "            summary_file = f\"{asset_key}_backtest_summary.csv\"\n",
    "            try:\n",
    "                with open(summary_file, \"rb\") as fp: st.download_button(label=f\"Download {asset_key.title()} Summary\", data=fp, file_name=summary_file, mime=\"text/csv\", key=f\"summary_{asset_key}\")\n",
    "            except FileNotFoundError: st.warning(f\"File '{summary_file}' not found.\")\n",
    "\n",
    "def main_app():\n",
    "    st.markdown(\"<h1 style='text-align: center;'>Crypto Price Prediction Engine</h1>\", unsafe_allow_html=True)\n",
    "    if 'page' not in st.session_state: st.session_state.page = \"Home\"\n",
    "    st.sidebar.title(\"Navigation\")\n",
    "    st.sidebar.radio(\"Go to\", [\"Home\", \"Strategy Dashboard\", \"Technical Details\"], key=\"page\")\n",
    "    if st.session_state.page == \"Home\": render_landing_page()\n",
    "    elif st.session_state.page == \"Strategy Dashboard\": render_backtester_page()\n",
    "    elif st.session_state.page == \"Technical Details\": render_details_page()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8f5f7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Parthiva\\AppData\\Local\\Temp\\ipykernel_2956\\410100660.py:20: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created 'final_featured_data.csv' with 3469960 rows.\n",
      "\n",
      "\n",
      "--- Data Summary Report ---\n",
      "File Name: final_featured_data.csv\n",
      "Total Rows: 3469960\n",
      "Total Columns: 10\n",
      "--------------------------------\n",
      "\n",
      "--- 1. Column Names and Data Types ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3469960 entries, 0 to 3469959\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   Timestamp      float64\n",
      " 1   Open           float64\n",
      " 2   High           float64\n",
      " 3   Low            float64\n",
      " 4   Close          float64\n",
      " 5   Volume         float64\n",
      " 6   Next_Day_Open  float64\n",
      " 7   SMA_10         float64\n",
      " 8   SMA_50         float64\n",
      " 9   RSI            float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 264.7 MB\n",
      "None\n",
      "\n",
      "--------------------------------\n",
      "\n",
      "--- 2. Data Preview (First 5 Rows) ---\n",
      "      Timestamp     Open     High      Low    Close     Volume  Next_Day_Open  \\\n",
      "0  1.546304e+09  3659.08  3670.88  3651.61  3670.15  19.265101        3659.35   \n",
      "1  1.546304e+09  3670.32  3681.29  3660.73  3678.78  41.974808        3659.35   \n",
      "2  1.546304e+09  3678.81  3678.81  3664.39  3675.20  26.156913        3659.35   \n",
      "3  1.546304e+09  3676.92  3677.14  3668.97  3670.78  12.779138        3659.35   \n",
      "4  1.546304e+09  3674.60  3676.26  3672.72  3672.72   1.708496        3659.35   \n",
      "\n",
      "     SMA_10     SMA_50        RSI  \n",
      "0  3686.781  3732.8490  25.609292  \n",
      "1  3681.152  3731.3844  28.320695  \n",
      "2  3675.222  3729.8482  27.713944  \n",
      "3  3669.156  3728.2236  27.707311  \n",
      "4  3664.026  3726.6378  31.145107  \n",
      "\n",
      "--------------------------------\n",
      "\n",
      "--- 3. Missing Values Check ---\n",
      "Count of null values in each column:\n",
      "Timestamp        0\n",
      "Open             0\n",
      "High             0\n",
      "Low              0\n",
      "Close            0\n",
      "Volume           0\n",
      "Next_Day_Open    0\n",
      "SMA_10           0\n",
      "SMA_50           0\n",
      "RSI              0\n",
      "dtype: int64\n",
      "\n",
      "--------------------------------\n",
      "\n",
      "--- 4. Descriptive Statistics ---\n",
      "             Timestamp         Open         High          Low        Close  \\\n",
      "count     3,469,960.00 3,469,960.00 3,469,960.00 3,469,960.00 3,469,960.00   \n",
      "mean  1,650,466,395.43    37,639.55    37,652.86    37,626.00    37,639.57   \n",
      "std      60,149,917.66    28,934.79    28,941.90    28,927.44    28,934.74   \n",
      "min   1,546,303,740.00     3,334.00     3,346.12     3,322.19     3,334.00   \n",
      "25%   1,598,375,925.00    11,356.22    11,360.75    11,352.17    11,356.41   \n",
      "50%   1,650,456,570.00    29,780.01    29,788.00    29,772.84    29,780.00   \n",
      "75%   1,702,552,455.00    56,658.24    56,685.31    56,630.60    56,658.90   \n",
      "max   1,754,697,420.00   123,110.00   123,236.00   123,007.00   123,236.00   \n",
      "\n",
      "            Volume  Next_Day_Open       SMA_10       SMA_50          RSI  \n",
      "count 3,469,960.00   3,469,960.00 3,469,960.00 3,469,960.00 3,469,960.00  \n",
      "mean          3.03      37,660.53    37,639.42    37,638.77        50.29  \n",
      "std          10.28      28,956.13    28,934.59    28,933.93        15.97  \n",
      "min           0.00       3,360.18     3,348.27     3,353.47         0.00  \n",
      "25%           0.06      11,344.60    11,356.55    11,356.89        39.35  \n",
      "50%           0.44      29,712.00    29,781.01    29,781.84        50.10  \n",
      "75%           2.12      56,879.00    56,658.72    56,656.58        61.11  \n",
      "max       1,098.35     120,011.00   122,947.60   122,670.10       100.00  \n",
      "\n",
      "--- End of Report ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def engineer_features(input_filename=\"final_processed_data.csv\", \n",
    "                      output_filename=\"final_featured_data.csv\"):\n",
    "    \"\"\"\n",
    "    Loads processed data, handles missing values, and engineers new features\n",
    "    (SMA, RSI) to create a dataset ready for model training.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(input_filename)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file '{input_filename}' not found. Aborting.\")\n",
    "        return None # Return None on failure\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"Input file is empty. No data to process.\")\n",
    "        return None\n",
    "\n",
    "    # --- Step 1: Handle Missing Data ---\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    df.dropna(inplace=True) \n",
    "\n",
    "    # --- Step 2: Feature Engineering ---\n",
    "    df['SMA_10'] = df['Close'].rolling(window=10).mean()\n",
    "    df['SMA_50'] = df['Close'].rolling(window=50).mean()\n",
    "\n",
    "    delta = df['Close'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=14).mean()\n",
    "    avg_loss = loss.rolling(window=14).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # --- Step 3: Save the Final Dataset ---\n",
    "    df.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(f\"Successfully created '{output_filename}' with {len(df)} rows.\")\n",
    "    return output_filename\n",
    "\n",
    "\n",
    "def generate_summary_report(filename):\n",
    "    \"\"\"\n",
    "    Reads a CSV file and prints a detailed summary report.\n",
    "    \"\"\"\n",
    "    if filename is None:\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        df = pd.read_csv(filename)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find file '{filename}' to generate a report.\")\n",
    "        return\n",
    "        \n",
    "    print(\"\\n\\n--- Data Summary Report ---\")\n",
    "    print(f\"File Name: {filename}\")\n",
    "    print(f\"Total Rows: {len(df)}\")\n",
    "    print(f\"Total Columns: {len(df.columns)}\")\n",
    "    print(\"--------------------------------\\n\")\n",
    "\n",
    "    print(\"--- 1. Column Names and Data Types ---\")\n",
    "    print(df.info())\n",
    "    print(\"\\n--------------------------------\\n\")\n",
    "\n",
    "    print(\"--- 2. Data Preview (First 5 Rows) ---\")\n",
    "    print(df.head())\n",
    "    print(\"\\n--------------------------------\\n\")\n",
    "\n",
    "    print(\"--- 3. Missing Values Check ---\")\n",
    "    print(\"Count of null values in each column:\")\n",
    "    print(df.isna().sum())\n",
    "    print(\"\\n--------------------------------\\n\")\n",
    "\n",
    "    print(\"--- 4. Descriptive Statistics ---\")\n",
    "    # Use a more readable float format for the statistics\n",
    "    with pd.option_context('display.float_format', '{:,.2f}'.format):\n",
    "        print(df.describe())\n",
    "    print(\"\\n--- End of Report ---\")\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # First, run the feature engineering process\n",
    "    final_file = engineer_features()\n",
    "    \n",
    "    # Then, generate a summary report on the file it just created\n",
    "    generate_summary_report(final_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12495029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Final Preparation: Splitting and Scaling ---\n",
      "1. Reading feature-rich data from 'final_featured_data_v2.csv'...\n",
      "2. Separating features (X) from the target (y)...\n",
      "   Feature shape (X): (0, 9)\n",
      "   Target shape (y): (0,)\n",
      "3. Splitting data chronologically into training (70%), validation (15%), and test (15%) sets...\n",
      "   Training set size:   0 rows\n",
      "   Validation set size: 0 rows\n",
      "   Test set size:       0 rows\n",
      "4. Scaling features using MinMaxScaler (values will be between 0 and 1)...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 9)) while a minimum of 1 is required by MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 92\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# Execute the main function\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[43msplit_and_scale_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 61\u001b[39m, in \u001b[36msplit_and_scale_data\u001b[39m\u001b[34m(input_filename, output_filename)\u001b[39m\n\u001b[32m     57\u001b[39m scaler = MinMaxScaler()\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# IMPORTANT: We fit the scaler ONLY on the training data. This prevents\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# information from the validation and test sets from \"leaking\" into the training process.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Now we use the FITTED scaler to transform all three data splits.\u001b[39;00m\n\u001b[32m     64\u001b[39m X_train_scaled = scaler.transform(X_train)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:454\u001b[39m, in \u001b[36mMinMaxScaler.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    452\u001b[39m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[38;5;28mself\u001b[39m._reset()\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:494\u001b[39m, in \u001b[36mMinMaxScaler.partial_fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    491\u001b[39m xp, _ = get_namespace(X)\n\u001b[32m    493\u001b[39m first_pass = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mn_samples_seen_\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfirst_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_array_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    502\u001b[39m device_ = device(X)\n\u001b[32m    503\u001b[39m feature_range = (\n\u001b[32m    504\u001b[39m     xp.asarray(feature_range[\u001b[32m0\u001b[39m], dtype=X.dtype, device=device_),\n\u001b[32m    505\u001b[39m     xp.asarray(feature_range[\u001b[32m1\u001b[39m], dtype=X.dtype, device=device_),\n\u001b[32m    506\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2954\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2952\u001b[39m         out = X, y\n\u001b[32m   2953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2955\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1128\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1126\u001b[39m     n_samples = _num_samples(array)\n\u001b[32m   1127\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_samples < ensure_min_samples:\n\u001b[32m-> \u001b[39m\u001b[32m1128\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1129\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) while a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1130\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1131\u001b[39m             % (n_samples, array.shape, ensure_min_samples, context)\n\u001b[32m   1132\u001b[39m         )\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m   1135\u001b[39m     n_features = array.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Found array with 0 sample(s) (shape=(0, 9)) while a minimum of 1 is required by MinMaxScaler."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def split_and_scale_data(input_filename=\"final_featured_data_v2.csv\", \n",
    "                         output_filename=\"model_ready_data_v2.npz\"):\n",
    "    \"\"\"\n",
    "    Loads the feature-rich dataset, splits it into chronological training,\n",
    "    validation, and test sets, scales the features, and saves the arrays.\n",
    "\n",
    "    Args:\n",
    "        input_filename (str): The name of the feature-rich CSV file.\n",
    "        output_filename (str): The name for the final compressed NumPy file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"--- Starting Final Preparation: Splitting and Scaling ---\")\n",
    "        print(f\"1. Reading feature-rich data from '{input_filename}'...\")\n",
    "        df = pd.read_csv(input_filename)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file '{input_filename}' not found. Please ensure it's in the correct directory and run the previous script if needed.\")\n",
    "        return\n",
    "\n",
    "    # --- Step 1: Separate Features (X) and Target (y) ---\n",
    "    print(\"2. Separating features (X) from the target (y)...\")\n",
    "    \n",
    "    # The target 'y' is the column we want to predict.\n",
    "    y = df['Next_Day_Open'].values\n",
    "    \n",
    "    # The features 'X' are all the columns we use for prediction.\n",
    "    # We drop the target itself and the original Timestamp. The timestamp's sequence\n",
    "    # is implicitly handled by our chronological split, and its large numerical value\n",
    "    # would disrupt the scaling process.\n",
    "    X = df.drop(columns=['Next_Day_Open', 'Timestamp']).values\n",
    "\n",
    "    print(f\"   Feature shape (X): {X.shape}\")\n",
    "    print(f\"   Target shape (y): {y.shape}\")\n",
    "\n",
    "    # --- Step 2: Chronological Data Splitting ---\n",
    "    print(\"3. Splitting data chronologically into training (70%), validation (15%), and test (15%) sets...\")\n",
    "    \n",
    "    n_total = len(X)\n",
    "    n_train = int(n_total * 0.70)\n",
    "    n_val = int(n_total * 0.15)\n",
    "    \n",
    "    # Slicing the arrays chronologically to prevent data leakage\n",
    "    X_train, y_train = X[:n_train], y[:n_train]\n",
    "    X_val, y_val = X[n_train:n_train + n_val], y[n_train:n_train + n_val]\n",
    "    X_test, y_test = X[n_train + n_val:], y[n_train + n_val:]\n",
    "\n",
    "    print(f\"   Training set size:   {len(X_train)} rows\")\n",
    "    print(f\"   Validation set size: {len(X_val)} rows\")\n",
    "    print(f\"   Test set size:       {len(X_test)} rows\")\n",
    "\n",
    "    # --- Step 3: Feature Scaling ---\n",
    "    print(\"4. Scaling features using MinMaxScaler (values will be between 0 and 1)...\")\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # IMPORTANT: We fit the scaler ONLY on the training data. This prevents\n",
    "    # information from the validation and test sets from \"leaking\" into the training process.\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    # Now we use the FITTED scaler to transform all three data splits.\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    print(\"   Scaling complete.\")\n",
    "\n",
    "    # --- Step 4: Save the Final Arrays ---\n",
    "    print(f\"5. Saving all processed arrays to a single compressed file: '{output_filename}'\")\n",
    "    \n",
    "    # We save the scaler object itself so we can use it later to process new,\n",
    "    # incoming data for real-time predictions.\n",
    "    np.savez_compressed(\n",
    "        output_filename,\n",
    "        X_train=X_train_scaled,\n",
    "        y_train=y_train,\n",
    "        X_val=X_val_scaled,\n",
    "        y_val=y_val,\n",
    "        X_test=X_test_scaled,\n",
    "        y_test=y_test,\n",
    "        scaler=np.array([scaler]) \n",
    "    )\n",
    "\n",
    "    print(f\"--- Final Preparation Complete ---\")\n",
    "    print(\"\\nSuccess! The data is now fully prepared for model training.\")\n",
    "    print(\"Let me know once you have run this script.\")\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    split_and_scale_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194bd355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Model Training and Comparison ---\n",
      "1. Loading data from 'model_ready_data.npz'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Model: Ridge ---\n",
      "   Making predictions...\n",
      "   Done in 0.14 seconds. MAE: $1,076.30, R²: 0.9918\n",
      "   *** New best model found: Ridge! ***\n",
      "\n",
      "--- Training Model: LightGBM ---\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2040\n",
      "[LightGBM] [Info] Number of data points in the train set: 2428972, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 20115.380859\n",
      "   Making predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Done in 33.53 seconds. MAE: $25,865.35, R²: -1.9187\n",
      "\n",
      "--- Training Model: MLP ---\n",
      "Epoch 1/100\n",
      "\u001b[1m9489/9489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - loss: 2296.4014 - val_loss: 1098.1342\n",
      "Epoch 2/100\n",
      "\u001b[1m9489/9489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 1436.0698 - val_loss: 6954.8740\n",
      "Epoch 3/100\n",
      "\u001b[1m9489/9489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 1164.3362 - val_loss: 8397.1797\n",
      "Epoch 4/100\n",
      "\u001b[1m9489/9489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 1122.4083 - val_loss: 8424.7139\n",
      "Epoch 5/100\n",
      "\u001b[1m9489/9489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 1099.7211 - val_loss: 8113.3242\n",
      "Epoch 6/100\n",
      "\u001b[1m9489/9489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 1089.5310 - val_loss: 8011.9785\n",
      "Epoch 7/100\n",
      "\u001b[1m9489/9489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 1078.7562 - val_loss: 7831.3286\n",
      "Epoch 8/100\n",
      "\u001b[1m9489/9489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 1069.2046 - val_loss: 7579.9482\n",
      "Epoch 9/100\n",
      "\u001b[1m9489/9489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 1054.3661 - val_loss: 7419.2109\n",
      "Epoch 10/100\n",
      "\u001b[1m9489/9489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 1041.5293 - val_loss: 8117.0967\n",
      "Epoch 11/100\n",
      "\u001b[1m9489/9489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step - loss: 1026.8265 - val_loss: 8644.0205\n",
      "   Making predictions...\n",
      "\u001b[1m16266/16266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 453us/step\n",
      "   Done in 144.44 seconds. MAE: $1,928.23, R²: 0.9830\n",
      "\n",
      "\n",
      "--- Final Model Comparison ---\n",
      "      Model           MAE  R2_Score  Training_Time_sec\n",
      "0     Ridge   1076.304037  0.991841           0.144181\n",
      "1       MLP   1928.225070  0.983050         144.442817\n",
      "2  LightGBM  25865.348294 -1.918705          33.527297\n",
      "\n",
      "--- Saving Champion Model ---\n",
      "The best performing model was Ridge with an MAE of $1,076.30.\n",
      "Saved champion model to 'champion_model_ridge.joblib'\n",
      "Saved data scaler to 'data_scaler.joblib'\n",
      "--- Process Complete ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "# Model Imports\n",
    "from sklearn.linear_model import Ridge\n",
    "import lightgbm as lgb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "def create_mlp_model(input_dim):\n",
    "    \"\"\"Creates a simple Multi-Layer Perceptron (MLP) model for regression.\"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        # The final layer has 1 neuron because we are predicting a single value (price).\n",
    "        Dense(1) \n",
    "    ])\n",
    "    # Compile the model with a good optimizer and a loss function suitable for price prediction.\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "def train_and_compare(data_filename=\"model_ready_data.npz\"):\n",
    "    \"\"\"\n",
    "    Loads data, trains multiple models, compares their performance,\n",
    "    and saves the best one.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Model Training and Comparison ---\")\n",
    "    \n",
    "    # 1. Load Data\n",
    "    print(f\"1. Loading data from '{data_filename}'...\")\n",
    "    with np.load(data_filename, allow_pickle=True) as data:\n",
    "        X_train, y_train = data['X_train'], data['y_train']\n",
    "        X_val, y_val = data['X_val'], data['y_val']\n",
    "        X_test, y_test = data['X_test'], data['y_test']\n",
    "        scaler = data['scaler'][0]\n",
    "\n",
    "    # 2. Define Models\n",
    "    models = {\n",
    "        \"Ridge\": Ridge(alpha=1.0),\n",
    "        \"LightGBM\": lgb.LGBMRegressor(objective='regression_l1', n_estimators=1000, random_state=42, n_jobs=-1),\n",
    "        \"MLP\": create_mlp_model(X_train.shape[1])\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    best_model = None\n",
    "    best_mae = float('inf')\n",
    "\n",
    "    # 3. Train and Evaluate Each Model\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n--- Training Model: {name} ---\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        if name == \"MLP\":\n",
    "            # Deep learning models need a validation set for early stopping\n",
    "            early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "            model.fit(X_train, y_train, \n",
    "                      validation_data=(X_val, y_val), \n",
    "                      epochs=100, \n",
    "                      batch_size=256, \n",
    "                      callbacks=[early_stop],\n",
    "                      verbose=1)\n",
    "        else:\n",
    "            # Scikit-learn models use a different API\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"   Making predictions...\")\n",
    "        predictions = model.predict(X_test).flatten() # Flatten for MLP compatibility\n",
    "\n",
    "        # Calculate metrics\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        \n",
    "        print(f\"   Done in {training_time:.2f} seconds. MAE: ${mae:,.2f}, R²: {r2:.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"MAE\": mae,\n",
    "            \"R2_Score\": r2,\n",
    "            \"Training_Time_sec\": training_time\n",
    "        })\n",
    "\n",
    "        # Check if this is the best model so far\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_model = model\n",
    "            print(f\"   *** New best model found: {name}! ***\")\n",
    "\n",
    "    # 4. Present Final Summary\n",
    "    print(\"\\n\\n--- Final Model Comparison ---\")\n",
    "    results_df = pd.DataFrame(results).sort_values(by=\"MAE\").reset_index(drop=True)\n",
    "    print(results_df)\n",
    "    \n",
    "    # 5. Save the Champion Model\n",
    "    champion_model_info = results_df.iloc[0]\n",
    "    champion_name = champion_model_info['Model']\n",
    "    champion_filename = f\"champion_model_{champion_name.lower()}.joblib\"\n",
    "    \n",
    "    print(f\"\\n--- Saving Champion Model ---\")\n",
    "    print(f\"The best performing model was {champion_name} with an MAE of ${champion_model_info['MAE']:,.2f}.\")\n",
    "    \n",
    "    if champion_name == \"MLP\":\n",
    "        # Keras models have their own saving format\n",
    "        champion_filename = f\"champion_model_{champion_name.lower()}.h5\"\n",
    "        best_model.save(champion_filename)\n",
    "    else:\n",
    "        joblib.dump(best_model, champion_filename)\n",
    "\n",
    "    # Always save the scaler, it's essential for any model\n",
    "    joblib.dump(scaler, 'data_scaler.joblib')\n",
    "    print(f\"Saved champion model to '{champion_filename}'\")\n",
    "    print(f\"Saved data scaler to 'data_scaler.joblib'\")\n",
    "    print(\"--- Process Complete ---\")\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_compare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "509a1387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Realistic Data Preparation (v2) ---\n",
      "1. Reading data from 'btcusd_1-min_data.csv'...\n",
      "2. Engineering features (SMA and RSI)...\n",
      "3. Creating realistic target 'Price_24h_Ahead' by shifting 1440 minutes...\n",
      "4. Cleaning data by dropping rows with NaN values...\n",
      "5. Saving final processed data to 'final_featured_data_v2.csv'...\n",
      "\n",
      "--- Realistic Data Preparation Complete ---\n",
      "Successfully created 'final_featured_data_v2.csv' with 6681455 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def prepare_realistic_data(raw_input_file=\"btcusd_1-min_data.csv\", \n",
    "                           final_output_file=\"final_featured_data_v2.csv\",\n",
    "                           prediction_horizon_minutes=1440): # 24 hours * 60 minutes\n",
    "    \"\"\"\n",
    "    Performs a full preprocessing pipeline with a realistic prediction target\n",
    "    to prevent data leakage.\n",
    "    \n",
    "    1. Loads raw data.\n",
    "    2. Engineers features (SMA, RSI).\n",
    "    3. Creates a realistic target by shifting the price into the future.\n",
    "    4. Cleans and saves the final data.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Realistic Data Preparation (v2) ---\")\n",
    "    \n",
    "    try:\n",
    "        print(f\"1. Reading data from '{raw_input_file}'...\")\n",
    "        df = pd.read_csv(raw_input_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Raw input file '{raw_input_file}' not found. Aborting.\")\n",
    "        return\n",
    "\n",
    "    # --- Step 1: Feature Engineering ---\n",
    "    print(\"2. Engineering features (SMA and RSI)...\")\n",
    "    df['SMA_10'] = df['Close'].rolling(window=10).mean()\n",
    "    df['SMA_50'] = df['Close'].rolling(window=50).mean()\n",
    "\n",
    "    delta = df['Close'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=14).mean()\n",
    "    avg_loss = loss.rolling(window=14).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # --- Step 2: Create a REALISTIC Prediction Target ---\n",
    "    print(f\"3. Creating realistic target 'Price_24h_Ahead' by shifting {prediction_horizon_minutes} minutes...\")\n",
    "    # This is the key change. We are predicting the opening price 1440 periods (minutes) in the future.\n",
    "    df['Price_24h_Ahead'] = df['Open'].shift(-prediction_horizon_minutes)\n",
    "\n",
    "    # --- Step 3: Clean Up and Finalize ---\n",
    "    print(\"4. Cleaning data by dropping rows with NaN values...\")\n",
    "    # Drop initial rows that don't have SMA/RSI values\n",
    "    # AND drop the final rows that don't have a future target value\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    print(f\"5. Saving final processed data to '{final_output_file}'...\")\n",
    "    df.to_csv(final_output_file, index=False)\n",
    "    \n",
    "    print(\"\\n--- Realistic Data Preparation Complete ---\")\n",
    "    print(f\"Successfully created '{final_output_file}' with {len(df)} rows.\")\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # We'll use the original processed file as input, not the feature-engineered one\n",
    "    prepare_realistic_data(raw_input_file=\"btcusd_1-min_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a67e8e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Final Preparation: Splitting and Scaling (v2) ---\n",
      "1. Reading corrected data from 'final_featured_data_v2.csv'...\n",
      "2. Separating features (X) from the target (y)...\n",
      "   Feature shape (X): (6681455, 8)\n",
      "   Target shape (y): (6681455,)\n",
      "3. Splitting data chronologically into training (70%), validation (15%), and test (15%) sets...\n",
      "   Training set size:   4677018 rows\n",
      "   Validation set size: 1002218 rows\n",
      "   Test set size:       1002219 rows\n",
      "4. Scaling features using MinMaxScaler...\n",
      "   Scaling complete.\n",
      "5. Saving all processed arrays to a single compressed file: 'model_ready_data.npz'\n",
      "--- Final Preparation Complete ---\n",
      "\n",
      "Success! The correctly prepared data is now ready for model training.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# --- CHANGED: Default input filename is now the 'v2' file ---\n",
    "def split_and_scale_data(input_filename=\"final_featured_data_v2.csv\", \n",
    "                         output_filename=\"model_ready_data.npz\"):\n",
    "    \"\"\"\n",
    "    Loads the feature-rich dataset (v2), splits it into chronological sets,\n",
    "    scales the features, and saves the arrays.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"--- Starting Final Preparation: Splitting and Scaling (v2) ---\")\n",
    "        print(f\"1. Reading corrected data from '{input_filename}'...\")\n",
    "        df = pd.read_csv(input_filename)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file '{input_filename}' not found. Please ensure it's in the correct directory.\")\n",
    "        return\n",
    "\n",
    "    print(\"2. Separating features (X) from the target (y)...\")\n",
    "    \n",
    "    # --- CHANGED: The target 'y' is now 'Price_24h_Ahead' ---\n",
    "    y = df['Price_24h_Ahead'].values\n",
    "    \n",
    "    # --- CHANGED: We now drop 'Price_24h_Ahead' to create our features 'X' ---\n",
    "    X = df.drop(columns=['Price_24h_Ahead', 'Timestamp']).values\n",
    "\n",
    "    print(f\"   Feature shape (X): {X.shape}\")\n",
    "    print(f\"   Target shape (y): {y.shape}\")\n",
    "\n",
    "    print(\"3. Splitting data chronologically into training (70%), validation (15%), and test (15%) sets...\")\n",
    "    \n",
    "    n_total = len(X)\n",
    "    n_train = int(n_total * 0.70)\n",
    "    n_val = int(n_total * 0.15)\n",
    "    \n",
    "    X_train, y_train = X[:n_train], y[:n_train]\n",
    "    X_val, y_val = X[n_train:n_train + n_val], y[n_train:n_train + n_val]\n",
    "    X_test, y_test = X[n_train + n_val:], y[n_train + n_val:]\n",
    "\n",
    "    print(f\"   Training set size:   {len(X_train)} rows\")\n",
    "    print(f\"   Validation set size: {len(X_val)} rows\")\n",
    "    print(f\"   Test set size:       {len(X_test)} rows\")\n",
    "\n",
    "    print(\"4. Scaling features using MinMaxScaler...\")\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    print(\"   Scaling complete.\")\n",
    "\n",
    "    print(f\"5. Saving all processed arrays to a single compressed file: '{output_filename}'\")\n",
    "    \n",
    "    np.savez_compressed(\n",
    "        output_filename,\n",
    "        X_train=X_train_scaled,\n",
    "        y_train=y_train,\n",
    "        X_val=X_val_scaled,\n",
    "        y_val=y_val,\n",
    "        X_test=X_test_scaled,\n",
    "        y_test=y_test,\n",
    "        scaler=np.array([scaler]) \n",
    "    )\n",
    "\n",
    "    print(f\"--- Final Preparation Complete ---\")\n",
    "    print(\"\\nSuccess! The correctly prepared data is now ready for model training.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    split_and_scale_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3ce9b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Model Training and Comparison ---\n",
      "1. Loading data from 'model_ready_data.npz'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Model: Ridge ---\n",
      "   Making predictions...\n",
      "   Done in 0.29 seconds. MAE: $1,249.87, R²: 0.9949\n",
      "   *** New best model found: Ridge! ***\n",
      "\n",
      "--- Training Model: LightGBM ---\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2040\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677018, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 1518.989990\n",
      "   Making predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Done in 64.17 seconds. MAE: $17,507.33, R²: -0.0223\n",
      "\n",
      "--- Training Model: MLP ---\n",
      "Epoch 1/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 692.1328 - val_loss: 1168.4974\n",
      "Epoch 2/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 479.1983 - val_loss: 4871.1260\n",
      "Epoch 3/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 421.5800 - val_loss: 5811.8945\n",
      "Epoch 4/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 419.0830 - val_loss: 5471.6250\n",
      "Epoch 5/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 414.1847 - val_loss: 5647.2769\n",
      "Epoch 6/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 403.3896 - val_loss: 6353.0693\n",
      "Epoch 7/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1ms/step - loss: 389.4268 - val_loss: 6180.8257\n",
      "Epoch 8/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 379.4682 - val_loss: 6272.7715\n",
      "Epoch 9/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 368.8520 - val_loss: 5936.4473\n",
      "Epoch 10/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 359.7484 - val_loss: 6148.6660\n",
      "Epoch 11/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 350.1463 - val_loss: 6280.7773\n",
      "   Making predictions...\n",
      "\u001b[1m31320/31320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 452us/step\n",
      "   Done in 282.77 seconds. MAE: $2,748.65, R²: 0.9832\n",
      "\n",
      "\n",
      "--- Final Model Comparison ---\n",
      "      Model           MAE  R2_Score  Training_Time_sec\n",
      "0     Ridge   1249.871498  0.994908           0.292612\n",
      "1       MLP   2748.646890  0.983169         282.771966\n",
      "2  LightGBM  17507.326722 -0.022251          64.169664\n",
      "\n",
      "--- Saving Champion Model ---\n",
      "The best performing model was Ridge with an MAE of $1,249.87.\n",
      "Saved champion model to 'champion_model_ridge.joblib'\n",
      "Saved data scaler to 'data_scaler.joblib'\n",
      "--- Process Complete ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "# Model Imports\n",
    "from sklearn.linear_model import Ridge\n",
    "import lightgbm as lgb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "def create_mlp_model(input_dim):\n",
    "    \"\"\"Creates a simple Multi-Layer Perceptron (MLP) model for regression.\"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        # The final layer has 1 neuron because we are predicting a single value (price).\n",
    "        Dense(1) \n",
    "    ])\n",
    "    # Compile the model with a good optimizer and a loss function suitable for price prediction.\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "def train_and_compare(data_filename=\"model_ready_data.npz\"):\n",
    "    \"\"\"\n",
    "    Loads data, trains multiple models, compares their performance,\n",
    "    and saves the best one.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Model Training and Comparison ---\")\n",
    "    \n",
    "    # 1. Load Data\n",
    "    print(f\"1. Loading data from '{data_filename}'...\")\n",
    "    with np.load(data_filename, allow_pickle=True) as data:\n",
    "        X_train, y_train = data['X_train'], data['y_train']\n",
    "        X_val, y_val = data['X_val'], data['y_val']\n",
    "        X_test, y_test = data['X_test'], data['y_test']\n",
    "        scaler = data['scaler'][0]\n",
    "\n",
    "    # 2. Define Models\n",
    "    models = {\n",
    "        \"Ridge\": Ridge(alpha=1.0),\n",
    "        \"LightGBM\": lgb.LGBMRegressor(objective='regression_l1', n_estimators=1000, random_state=42, n_jobs=-1),\n",
    "        \"MLP\": create_mlp_model(X_train.shape[1])\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    best_model = None\n",
    "    best_mae = float('inf')\n",
    "\n",
    "    # 3. Train and Evaluate Each Model\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n--- Training Model: {name} ---\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        if name == \"MLP\":\n",
    "            # Deep learning models need a validation set for early stopping\n",
    "            early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "            model.fit(X_train, y_train, \n",
    "                      validation_data=(X_val, y_val), \n",
    "                      epochs=100, \n",
    "                      batch_size=256, \n",
    "                      callbacks=[early_stop],\n",
    "                      verbose=1)\n",
    "        else:\n",
    "            # Scikit-learn models use a different API\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"   Making predictions...\")\n",
    "        predictions = model.predict(X_test).flatten() # Flatten for MLP compatibility\n",
    "\n",
    "        # Calculate metrics\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        \n",
    "        print(f\"   Done in {training_time:.2f} seconds. MAE: ${mae:,.2f}, R²: {r2:.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"MAE\": mae,\n",
    "            \"R2_Score\": r2,\n",
    "            \"Training_Time_sec\": training_time\n",
    "        })\n",
    "\n",
    "        # Check if this is the best model so far\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_model = model\n",
    "            print(f\"   *** New best model found: {name}! ***\")\n",
    "\n",
    "    # 4. Present Final Summary\n",
    "    print(\"\\n\\n--- Final Model Comparison ---\")\n",
    "    results_df = pd.DataFrame(results).sort_values(by=\"MAE\").reset_index(drop=True)\n",
    "    print(results_df)\n",
    "    \n",
    "    # 5. Save the Champion Model\n",
    "    champion_model_info = results_df.iloc[0]\n",
    "    champion_name = champion_model_info['Model']\n",
    "    champion_filename = f\"champion_model_{champion_name.lower()}.joblib\"\n",
    "    \n",
    "    print(f\"\\n--- Saving Champion Model ---\")\n",
    "    print(f\"The best performing model was {champion_name} with an MAE of ${champion_model_info['MAE']:,.2f}.\")\n",
    "    \n",
    "    if champion_name == \"MLP\":\n",
    "        # Keras models have their own saving format\n",
    "        champion_filename = f\"champion_model_{champion_name.lower()}.h5\"\n",
    "        best_model.save(champion_filename)\n",
    "    else:\n",
    "        joblib.dump(best_model, champion_filename)\n",
    "\n",
    "    # Always save the scaler, it's essential for any model\n",
    "    joblib.dump(scaler, 'data_scaler.joblib')\n",
    "    print(f\"Saved champion model to '{champion_filename}'\")\n",
    "    print(f\"Saved data scaler to 'data_scaler.joblib'\")\n",
    "    print(\"--- Process Complete ---\")\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_compare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d539f6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Stationary Data Preparation (v3) ---\n",
      "1. Reading data from 'btcusd_1-min_data.csv'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Parthiva\\AppData\\Local\\Temp\\ipykernel_2956\\4172214031.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
      "C:\\Users\\Parthiva\\AppData\\Local\\Temp\\ipykernel_2956\\4172214031.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_df.dropna(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Saving final stationary data to 'final_featured_data_v3.csv'...\n",
      "\n",
      "--- Stationary Data Preparation Complete ---\n",
      "Successfully created 'final_featured_data_v3.csv' with 6681455 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def prepare_stationary_data(raw_input_file=\"btcusd_1-min_data.csv\", \n",
    "                            final_output_file=\"final_featured_data_v3.csv\",\n",
    "                            prediction_horizon_minutes=1440):\n",
    "    \"\"\"\n",
    "    Creates a stationary dataset with relative features and a percent-change target.\n",
    "    This is the professional approach to financial time-series modeling.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Stationary Data Preparation (v3) ---\")\n",
    "    \n",
    "    try:\n",
    "        print(f\"1. Reading data from '{raw_input_file}'...\")\n",
    "        df = pd.read_csv(raw_input_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Raw input file '{raw_input_file}' not found. Aborting.\")\n",
    "        return\n",
    "\n",
    "    # --- Step 1: Create Base Indicators ---\n",
    "    df['SMA_10'] = df['Close'].rolling(window=10).mean()\n",
    "    df['SMA_50'] = df['Close'].rolling(window=50).mean()\n",
    "    df['Volume_SMA_50'] = df['Volume'].rolling(window=50).mean()\n",
    "\n",
    "    delta = df['Close'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=14).mean()\n",
    "    avg_loss = loss.rolling(window=14).mean()\n",
    "    df['RSI'] = 100 - (100 / (1 + (avg_gain / avg_loss)))\n",
    "\n",
    "    # --- Step 2: Create the STATIONARY TARGET ---\n",
    "    # The target is the future percent change.\n",
    "    future_price = df['Open'].shift(-prediction_horizon_minutes)\n",
    "    df['Target_24h_Pct_Change'] = ((future_price - df['Close']) / df['Close']) * 100\n",
    "\n",
    "    # --- Step 3: Create STATIONARY FEATURES ---\n",
    "    # These features measure relationships, not absolute levels.\n",
    "    df['Feat_Close_vs_SMA10'] = (df['Close'] - df['SMA_10']) / df['SMA_10']\n",
    "    df['Feat_Close_vs_SMA50'] = (df['Close'] - df['SMA_50']) / df['SMA_50']\n",
    "    df['Feat_SMA10_vs_SMA50'] = (df['SMA_10'] - df['SMA_50']) / df['SMA_50']\n",
    "    df['Feat_Volume_vs_SMA50'] = (df['Volume'] - df['Volume_SMA_50']) / df['Volume_SMA_50']\n",
    "    # RSI is already a stationary feature (0-100), so we just rename it.\n",
    "    df['Feat_RSI'] = df['RSI']\n",
    "\n",
    "    # --- Step 4: Finalize the Dataset ---\n",
    "    # Select ONLY our new stationary features and target for the final model.\n",
    "    final_cols = [\n",
    "        'Target_24h_Pct_Change',\n",
    "        'Feat_RSI',\n",
    "        'Feat_Close_vs_SMA10',\n",
    "        'Feat_Close_vs_SMA50',\n",
    "        'Feat_SMA10_vs_SMA50',\n",
    "        'Feat_Volume_vs_SMA50'\n",
    "    ]\n",
    "    model_df = df[final_cols]\n",
    "\n",
    "    # Replace infinite values that can occur from division by zero with NaN, then drop all NaNs.\n",
    "    model_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    model_df.dropna(inplace=True)\n",
    "    model_df = model_df.reset_index(drop=True)\n",
    "\n",
    "    print(f\"5. Saving final stationary data to '{final_output_file}'...\")\n",
    "    model_df.to_csv(final_output_file, index=False)\n",
    "    \n",
    "    print(\"\\n--- Stationary Data Preparation Complete ---\")\n",
    "    print(f\"Successfully created '{final_output_file}' with {len(model_df)} rows.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    prepare_stationary_data(raw_input_file=\"btcusd_1-min_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "038dcd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Success! Stationary data saved to model_ready_data.npz\n"
     ]
    }
   ],
   "source": [
    "# scale_and_split_data.py (final version)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler # Using StandardScaler is often better for this type of data\n",
    "\n",
    "def split_and_scale_data(input_filename=\"final_featured_data_v3.csv\", \n",
    "                         output_filename=\"model_ready_data.npz\"):\n",
    "    df = pd.read_csv(input_filename)\n",
    "    y = df['Target_24h_Pct_Change'].values\n",
    "    X = df.drop(columns=['Target_24h_Pct_Change']).values\n",
    "\n",
    "    n_total = len(X)\n",
    "    n_train = int(n_total * 0.70)\n",
    "    n_val = int(n_total * 0.15)\n",
    "    \n",
    "    X_train, y_train = X[:n_train], y[:n_train]\n",
    "    X_val, y_val = X[n_train:n_train + n_val], y[n_train:n_train + n_val]\n",
    "    X_test, y_test = X[n_train + n_val:], y[n_train + n_val:]\n",
    "\n",
    "    scaler = StandardScaler() # StandardScaler centers the data around 0\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    np.savez_compressed(output_filename,\n",
    "        X_train=X_train_scaled, y_train=y_train,\n",
    "        X_val=X_val_scaled, y_val=y_val,\n",
    "        X_test=X_test_scaled, y_test=y_test,\n",
    "        scaler=np.array([scaler]))\n",
    "    print(f\"\\nSuccess! Stationary data saved to {output_filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    split_and_scale_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a46e5737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Model Training and Comparison ---\n",
      "1. Loading data from 'model_ready_data.npz'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Model: Ridge ---\n",
      "   Making predictions...\n",
      "   Done in 0.20 seconds. MAE: $1.78, R²: -0.0016\n",
      "   *** New best model found: Ridge! ***\n",
      "\n",
      "--- Training Model: LightGBM ---\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 4677018, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 0.210803\n",
      "   Making predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Done in 62.82 seconds. MAE: $1.77, R²: 0.0008\n",
      "   *** New best model found: LightGBM! ***\n",
      "\n",
      "--- Training Model: MLP ---\n",
      "Epoch 1/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - loss: 2.8608 - val_loss: 2.0665\n",
      "Epoch 2/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 2.8600 - val_loss: 2.0657\n",
      "Epoch 3/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 2.8598 - val_loss: 2.0675\n",
      "Epoch 4/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 2.8596 - val_loss: 2.0635\n",
      "Epoch 5/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 2.8594 - val_loss: 2.0628\n",
      "Epoch 6/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 2.8594 - val_loss: 2.0670\n",
      "Epoch 7/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 2.8594 - val_loss: 2.0680\n",
      "Epoch 8/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1ms/step - loss: 2.8592 - val_loss: 2.0645\n",
      "Epoch 9/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 2.8593 - val_loss: 2.0645\n",
      "Epoch 10/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 2.8592 - val_loss: 2.0664\n",
      "Epoch 11/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 2.8592 - val_loss: 2.0669\n",
      "Epoch 12/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 2.8591 - val_loss: 2.0690\n",
      "Epoch 13/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 2.8590 - val_loss: 2.0660\n",
      "Epoch 14/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 2.8589 - val_loss: 2.0627\n",
      "Epoch 15/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 2.8589 - val_loss: 2.0652\n",
      "Epoch 16/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 2.8589 - val_loss: 2.0652\n",
      "Epoch 17/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 2.8587 - val_loss: 2.0648\n",
      "Epoch 18/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 2.8588 - val_loss: 2.0635\n",
      "Epoch 19/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 2.8588 - val_loss: 2.0639\n",
      "Epoch 20/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 2.8587 - val_loss: 2.0664\n",
      "Epoch 21/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 2.8588 - val_loss: 2.0658\n",
      "Epoch 22/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 2.8587 - val_loss: 2.0643\n",
      "Epoch 23/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 2.8585 - val_loss: 2.0630\n",
      "Epoch 24/100\n",
      "\u001b[1m18270/18270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 2.8586 - val_loss: 2.0649\n",
      "   Making predictions...\n",
      "\u001b[1m31320/31320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 453us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Done in 654.19 seconds. MAE: $1.77, R²: 0.0005\n",
      "   *** New best model found: MLP! ***\n",
      "\n",
      "\n",
      "--- Final Model Comparison ---\n",
      "      Model       MAE  R2_Score  Training_Time_sec\n",
      "0       MLP  1.769139  0.000527         654.193912\n",
      "1  LightGBM  1.769766  0.000820          62.816509\n",
      "2     Ridge  1.782857 -0.001645           0.201247\n",
      "\n",
      "--- Saving Champion Model ---\n",
      "The best performing model was MLP with an MAE of $1.77.\n",
      "Saved champion model to 'champion_model_mlp.h5'\n",
      "Saved data scaler to 'data_scaler.joblib'\n",
      "--- Process Complete ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "# Model Imports\n",
    "from sklearn.linear_model import Ridge\n",
    "import lightgbm as lgb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "def create_mlp_model(input_dim):\n",
    "    \"\"\"Creates a simple Multi-Layer Perceptron (MLP) model for regression.\"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        # The final layer has 1 neuron because we are predicting a single value (price).\n",
    "        Dense(1) \n",
    "    ])\n",
    "    # Compile the model with a good optimizer and a loss function suitable for price prediction.\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "    return model\n",
    "\n",
    "def train_and_compare(data_filename=\"model_ready_data.npz\"):\n",
    "    \"\"\"\n",
    "    Loads data, trains multiple models, compares their performance,\n",
    "    and saves the best one.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Model Training and Comparison ---\")\n",
    "    \n",
    "    # 1. Load Data\n",
    "    print(f\"1. Loading data from '{data_filename}'...\")\n",
    "    with np.load(data_filename, allow_pickle=True) as data:\n",
    "        X_train, y_train = data['X_train'], data['y_train']\n",
    "        X_val, y_val = data['X_val'], data['y_val']\n",
    "        X_test, y_test = data['X_test'], data['y_test']\n",
    "        scaler = data['scaler'][0]\n",
    "\n",
    "    # 2. Define Models\n",
    "    models = {\n",
    "        \"Ridge\": Ridge(alpha=1.0),\n",
    "        \"LightGBM\": lgb.LGBMRegressor(objective='regression_l1', n_estimators=1000, random_state=42, n_jobs=-1),\n",
    "        \"MLP\": create_mlp_model(X_train.shape[1])\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    best_model = None\n",
    "    best_mae = float('inf')\n",
    "\n",
    "    # 3. Train and Evaluate Each Model\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n--- Training Model: {name} ---\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        if name == \"MLP\":\n",
    "            # Deep learning models need a validation set for early stopping\n",
    "            early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "            model.fit(X_train, y_train, \n",
    "                      validation_data=(X_val, y_val), \n",
    "                      epochs=100, \n",
    "                      batch_size=256, \n",
    "                      callbacks=[early_stop],\n",
    "                      verbose=1)\n",
    "        else:\n",
    "            # Scikit-learn models use a different API\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"   Making predictions...\")\n",
    "        predictions = model.predict(X_test).flatten() # Flatten for MLP compatibility\n",
    "\n",
    "        # Calculate metrics\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        \n",
    "        print(f\"   Done in {training_time:.2f} seconds. MAE: ${mae:,.2f}, R²: {r2:.4f}\")\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"MAE\": mae,\n",
    "            \"R2_Score\": r2,\n",
    "            \"Training_Time_sec\": training_time\n",
    "        })\n",
    "\n",
    "        # Check if this is the best model so far\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_model = model\n",
    "            print(f\"   *** New best model found: {name}! ***\")\n",
    "\n",
    "    # 4. Present Final Summary\n",
    "    print(\"\\n\\n--- Final Model Comparison ---\")\n",
    "    results_df = pd.DataFrame(results).sort_values(by=\"MAE\").reset_index(drop=True)\n",
    "    print(results_df)\n",
    "    \n",
    "    # 5. Save the Champion Model\n",
    "    champion_model_info = results_df.iloc[0]\n",
    "    champion_name = champion_model_info['Model']\n",
    "    champion_filename = f\"champion_model_{champion_name.lower()}.joblib\"\n",
    "    \n",
    "    print(f\"\\n--- Saving Champion Model ---\")\n",
    "    print(f\"The best performing model was {champion_name} with an MAE of ${champion_model_info['MAE']:,.2f}.\")\n",
    "    \n",
    "    if champion_name == \"MLP\":\n",
    "        # Keras models have their own saving format\n",
    "        champion_filename = f\"champion_model_{champion_name.lower()}.h5\"\n",
    "        best_model.save(champion_filename)\n",
    "    else:\n",
    "        joblib.dump(best_model, champion_filename)\n",
    "\n",
    "    # Always save the scaler, it's essential for any model\n",
    "    joblib.dump(scaler, 'data_scaler.joblib')\n",
    "    print(f\"Saved champion model to '{champion_filename}'\")\n",
    "    print(f\"Saved data scaler to 'data_scaler.joblib'\")\n",
    "    print(\"--- Process Complete ---\")\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_compare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f986f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Hyperparameter Tuning for LightGBM ---\n",
      "1. Loading data from 'model_ready_data.npz'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 18:53:34,062] A new study created in memory with name: no-name-f8a08928-9c42-4868-ad84-df2b1c4a8e62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Running Optuna study to find best hyperparameters (this will take time)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:53:46,558] Trial 0 finished with value: 2.065309562829775 and parameters: {'learning_rate': 0.039454383564868876, 'num_leaves': 72, 'max_depth': 13, 'min_child_samples': 97, 'subsample': 0.8499299687555866, 'colsample_bytree': 0.6967460853118119}. Best is trial 0 with value: 2.065309562829775.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:53:56,673] Trial 1 finished with value: 2.065386940527988 and parameters: {'learning_rate': 0.0649646947820005, 'num_leaves': 95, 'max_depth': 14, 'min_child_samples': 130, 'subsample': 0.6069715727059722, 'colsample_bytree': 0.8382778082794398}. Best is trial 0 with value: 2.065309562829775.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:54:20,769] Trial 2 finished with value: 2.0653178778888517 and parameters: {'learning_rate': 0.019288816056042518, 'num_leaves': 79, 'max_depth': 10, 'min_child_samples': 160, 'subsample': 0.6738348487777526, 'colsample_bytree': 0.822276513869246}. Best is trial 0 with value: 2.065309562829775.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:54:29,342] Trial 3 finished with value: 2.0652819301031844 and parameters: {'learning_rate': 0.06942798440640494, 'num_leaves': 59, 'max_depth': 0, 'min_child_samples': 184, 'subsample': 0.6806304488273356, 'colsample_bytree': 0.6959435030327057}. Best is trial 3 with value: 2.0652819301031844.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:54:45,381] Trial 4 finished with value: 2.0652098529497875 and parameters: {'learning_rate': 0.044455226214280025, 'num_leaves': 92, 'max_depth': 3, 'min_child_samples': 114, 'subsample': 0.840613896887149, 'colsample_bytree': 0.781138200501718}. Best is trial 4 with value: 2.0652098529497875.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:54:56,285] Trial 5 finished with value: 2.065344441066841 and parameters: {'learning_rate': 0.06150548628473436, 'num_leaves': 68, 'max_depth': 11, 'min_child_samples': 184, 'subsample': 0.986048350255268, 'colsample_bytree': 0.727609276921505}. Best is trial 4 with value: 2.0652098529497875.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:55:12,510] Trial 6 finished with value: 2.0652867495570018 and parameters: {'learning_rate': 0.03561609388378145, 'num_leaves': 71, 'max_depth': -1, 'min_child_samples': 37, 'subsample': 0.8262047359869369, 'colsample_bytree': 0.8365711495057765}. Best is trial 4 with value: 2.0652098529497875.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:55:47,548] Trial 7 finished with value: 2.0652701269105567 and parameters: {'learning_rate': 0.010762995418294608, 'num_leaves': 54, 'max_depth': 9, 'min_child_samples': 119, 'subsample': 0.9281362902118464, 'colsample_bytree': 0.6968109934908577}. Best is trial 4 with value: 2.0652098529497875.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:55:54,557] Trial 8 finished with value: 2.0651566396134946 and parameters: {'learning_rate': 0.09740697515212225, 'num_leaves': 84, 'max_depth': 4, 'min_child_samples': 152, 'subsample': 0.8162779453176042, 'colsample_bytree': 0.6905610781252154}. Best is trial 8 with value: 2.0651566396134946.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:56:02,198] Trial 9 finished with value: 2.065156463385464 and parameters: {'learning_rate': 0.05410029505917883, 'num_leaves': 56, 'max_depth': 5, 'min_child_samples': 76, 'subsample': 0.6916792059901133, 'colsample_bytree': 0.6917864670620657}. Best is trial 9 with value: 2.065156463385464.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:56:10,834] Trial 10 finished with value: 2.065275889915312 and parameters: {'learning_rate': 0.08409427973110965, 'num_leaves': 33, 'max_depth': 6, 'min_child_samples': 61, 'subsample': 0.7228723798276451, 'colsample_bytree': 0.9611190411716272}. Best is trial 9 with value: 2.065156463385464.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:56:17,658] Trial 11 finished with value: 2.0650609187922666 and parameters: {'learning_rate': 0.09944725558723103, 'num_leaves': 42, 'max_depth': 5, 'min_child_samples': 81, 'subsample': 0.7494241074148139, 'colsample_bytree': 0.6108081327217696}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:56:25,864] Trial 12 finished with value: 2.0651394326335586 and parameters: {'learning_rate': 0.08063318692451119, 'num_leaves': 42, 'max_depth': 6, 'min_child_samples': 79, 'subsample': 0.7398376494950649, 'colsample_bytree': 0.6004376360215186}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:56:32,722] Trial 13 finished with value: 2.065149308015556 and parameters: {'learning_rate': 0.09793193078157504, 'num_leaves': 38, 'max_depth': 8, 'min_child_samples': 21, 'subsample': 0.7656111225738617, 'colsample_bytree': 0.6086189421418228}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:56:39,366] Trial 14 finished with value: 2.0651842174265473 and parameters: {'learning_rate': 0.08105909789550325, 'num_leaves': 43, 'max_depth': 3, 'min_child_samples': 81, 'subsample': 0.7504884650161493, 'colsample_bytree': 0.6021818225378944}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:56:57,707] Trial 15 finished with value: 2.0654562787141413 and parameters: {'learning_rate': 0.08325363019248805, 'num_leaves': 23, 'max_depth': 1, 'min_child_samples': 54, 'subsample': 0.6088370381595318, 'colsample_bytree': 0.6334651778223674}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:57:05,322] Trial 16 finished with value: 2.06525590131438 and parameters: {'learning_rate': 0.08976658652357208, 'num_leaves': 48, 'max_depth': 7, 'min_child_samples': 94, 'subsample': 0.7706915805481773, 'colsample_bytree': 0.9289477184091376}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:57:14,926] Trial 17 finished with value: 2.0653545534427042 and parameters: {'learning_rate': 0.07209378265415822, 'num_leaves': 27, 'max_depth': 2, 'min_child_samples': 57, 'subsample': 0.8683000785995065, 'colsample_bytree': 0.6425777406580354}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:57:21,971] Trial 18 finished with value: 2.0652589141071784 and parameters: {'learning_rate': 0.09945290381236739, 'num_leaves': 47, 'max_depth': 6, 'min_child_samples': 74, 'subsample': 0.7157057671829425, 'colsample_bytree': 0.7656365589258163}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:57:30,125] Trial 19 finished with value: 2.06523246730876 and parameters: {'learning_rate': 0.07649911031098132, 'num_leaves': 33, 'max_depth': 12, 'min_child_samples': 134, 'subsample': 0.8976147596207558, 'colsample_bytree': 0.9022437068910159}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:57:37,554] Trial 20 finished with value: 2.0651710973724113 and parameters: {'learning_rate': 0.08961755157403663, 'num_leaves': 50, 'max_depth': 8, 'min_child_samples': 38, 'subsample': 0.6480368267426856, 'colsample_bytree': 0.6485490757717968}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:57:44,012] Trial 21 finished with value: 2.065166059284059 and parameters: {'learning_rate': 0.09254458904561144, 'num_leaves': 37, 'max_depth': 8, 'min_child_samples': 24, 'subsample': 0.7809049573855432, 'colsample_bytree': 0.6062548242051498}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:57:51,368] Trial 22 finished with value: 2.065136044611625 and parameters: {'learning_rate': 0.09898347060675858, 'num_leaves': 41, 'max_depth': 5, 'min_child_samples': 20, 'subsample': 0.7489219218830103, 'colsample_bytree': 0.6473604379631845}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:57:58,196] Trial 23 finished with value: 2.06513355471181 and parameters: {'learning_rate': 0.08938661047233724, 'num_leaves': 42, 'max_depth': 5, 'min_child_samples': 96, 'subsample': 0.7332381604403565, 'colsample_bytree': 0.6594533355741061}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:58:07,073] Trial 24 finished with value: 2.065251334381692 and parameters: {'learning_rate': 0.09054252768602661, 'num_leaves': 64, 'max_depth': 4, 'min_child_samples': 102, 'subsample': 0.8031776736264306, 'colsample_bytree': 0.659131991703642}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:58:14,900] Trial 25 finished with value: 2.0651580569125043 and parameters: {'learning_rate': 0.09950814539450673, 'num_leaves': 30, 'max_depth': 4, 'min_child_samples': 39, 'subsample': 0.7067718448796432, 'colsample_bytree': 0.7324798502504385}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:58:26,299] Trial 26 finished with value: 2.065255317487479 and parameters: {'learning_rate': 0.08778463617437851, 'num_leaves': 21, 'max_depth': 2, 'min_child_samples': 128, 'subsample': 0.6484111962275394, 'colsample_bytree': 0.663529801417114}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:58:34,647] Trial 27 finished with value: 2.065221689913605 and parameters: {'learning_rate': 0.07688197550474472, 'num_leaves': 42, 'max_depth': 5, 'min_child_samples': 89, 'subsample': 0.7946778444987892, 'colsample_bytree': 0.7272105105510087}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:58:40,917] Trial 28 finished with value: 2.0652505665078587 and parameters: {'learning_rate': 0.09539314446598941, 'num_leaves': 50, 'max_depth': 7, 'min_child_samples': 65, 'subsample': 0.7405778870638698, 'colsample_bytree': 0.8786154683018368}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:58:50,029] Trial 29 finished with value: 2.06527162818394 and parameters: {'learning_rate': 0.05604551234865006, 'num_leaves': 61, 'max_depth': 15, 'min_child_samples': 47, 'subsample': 0.8645777185260014, 'colsample_bytree': 0.6746295857515174}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:59:16,214] Trial 30 finished with value: 2.065340615810852 and parameters: {'learning_rate': 0.03089094033447012, 'num_leaves': 37, 'max_depth': 2, 'min_child_samples': 105, 'subsample': 0.6548449623414855, 'colsample_bytree': 0.6329106796353018}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:59:22,948] Trial 31 finished with value: 2.065141918767402 and parameters: {'learning_rate': 0.08454906143159281, 'num_leaves': 42, 'max_depth': 6, 'min_child_samples': 88, 'subsample': 0.7392396500013116, 'colsample_bytree': 0.6259303981846221}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:59:30,373] Trial 32 finished with value: 2.0651558047392373 and parameters: {'learning_rate': 0.07592047796070296, 'num_leaves': 26, 'max_depth': 6, 'min_child_samples': 77, 'subsample': 0.7562265619798456, 'colsample_bytree': 0.6008880459914682}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:59:37,800] Trial 33 finished with value: 2.065147037848225 and parameters: {'learning_rate': 0.09324980712245484, 'num_leaves': 44, 'max_depth': 5, 'min_child_samples': 142, 'subsample': 0.719523299051024, 'colsample_bytree': 0.6258469797458945}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:59:46,390] Trial 34 finished with value: 2.0652934064996984 and parameters: {'learning_rate': 0.06444262073587165, 'num_leaves': 53, 'max_depth': 7, 'min_child_samples': 66, 'subsample': 0.7848999021508926, 'colsample_bytree': 0.7520174275555803}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 18:59:55,440] Trial 35 finished with value: 2.0652693173663765 and parameters: {'learning_rate': 0.08117047323876847, 'num_leaves': 37, 'max_depth': 10, 'min_child_samples': 196, 'subsample': 0.6917112579235506, 'colsample_bytree': 0.8026647047978758}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 19:00:01,705] Trial 36 finished with value: 2.0651570531502097 and parameters: {'learning_rate': 0.08749416738034158, 'num_leaves': 32, 'max_depth': 3, 'min_child_samples': 114, 'subsample': 0.6694119206920587, 'colsample_bytree': 0.6759581704901927}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 19:00:10,538] Trial 37 finished with value: 2.0652061451621186 and parameters: {'learning_rate': 0.0694746855593091, 'num_leaves': 78, 'max_depth': 5, 'min_child_samples': 102, 'subsample': 0.6194107079975187, 'colsample_bytree': 0.7146894882499035}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 19:00:18,046] Trial 38 finished with value: 2.065214695670773 and parameters: {'learning_rate': 0.09411195471681891, 'num_leaves': 59, 'max_depth': 9, 'min_child_samples': 86, 'subsample': 0.7361843200910763, 'colsample_bytree': 0.6571693699129056}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 19:00:25,726] Trial 39 finished with value: 2.065210909790137 and parameters: {'learning_rate': 0.07841938324772732, 'num_leaves': 45, 'max_depth': 0, 'min_child_samples': 120, 'subsample': 0.8248841344617523, 'colsample_bytree': 0.6227840862569108}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 19:00:35,033] Trial 40 finished with value: 2.065186894548962 and parameters: {'learning_rate': 0.04243178715089854, 'num_leaves': 54, 'max_depth': 4, 'min_child_samples': 168, 'subsample': 0.9954408601743898, 'colsample_bytree': 0.675321019879108}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 19:00:42,862] Trial 41 finished with value: 2.0651501004633532 and parameters: {'learning_rate': 0.08495992657097208, 'num_leaves': 40, 'max_depth': 6, 'min_child_samples': 89, 'subsample': 0.7411189384008201, 'colsample_bytree': 0.6229733011809925}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 19:00:49,240] Trial 42 finished with value: 2.0651629990954405 and parameters: {'learning_rate': 0.094111693923092, 'num_leaves': 40, 'max_depth': 5, 'min_child_samples': 72, 'subsample': 0.6993701480812501, 'colsample_bytree': 0.6458343718794002}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 19:00:56,579] Trial 43 finished with value: 2.065272504222389 and parameters: {'learning_rate': 0.08550220658258668, 'num_leaves': 35, 'max_depth': 9, 'min_child_samples': 93, 'subsample': 0.725070005225223, 'colsample_bytree': 0.7113482732707103}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 19:01:03,340] Trial 44 finished with value: 2.0651259365050505 and parameters: {'learning_rate': 0.09993215427571206, 'num_leaves': 28, 'max_depth': 6, 'min_child_samples': 49, 'subsample': 0.7647472385809139, 'colsample_bytree': 0.6251115679249926}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 19:01:10,274] Trial 45 finished with value: 2.065152352866618 and parameters: {'learning_rate': 0.09959781095812728, 'num_leaves': 30, 'max_depth': 7, 'min_child_samples': 27, 'subsample': 0.8088800260620006, 'colsample_bytree': 0.6158941094100344}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 19:01:17,148] Trial 46 finished with value: 2.065179216072096 and parameters: {'learning_rate': 0.09562836577286261, 'num_leaves': 26, 'max_depth': 4, 'min_child_samples': 49, 'subsample': 0.7700748947335828, 'colsample_bytree': 0.6930863849192079}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 19:01:23,941] Trial 47 finished with value: 2.0651559418559913 and parameters: {'learning_rate': 0.09053622831320277, 'num_leaves': 20, 'max_depth': 3, 'min_child_samples': 32, 'subsample': 0.7607973667780993, 'colsample_bytree': 0.6457239633720678}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 19:01:34,682] Trial 48 finished with value: 2.0651708203181935 and parameters: {'learning_rate': 0.05030995644671606, 'num_leaves': 29, 'max_depth': 8, 'min_child_samples': 50, 'subsample': 0.6826622281646237, 'colsample_bytree': 0.6006439565633922}. Best is trial 11 with value: 2.0650609187922666.\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2025-08-10 19:01:42,419] Trial 49 finished with value: 2.0652582674348885 and parameters: {'learning_rate': 0.0729810681796564, 'num_leaves': 47, 'max_depth': 6, 'min_child_samples': 43, 'subsample': 0.8400857442692178, 'colsample_bytree': 0.8580822729747631}. Best is trial 11 with value: 2.0650609187922666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning Complete ---\n",
      "Best MAE on validation set: 2.0651\n",
      "Best hyperparameters found:\n",
      "{'learning_rate': 0.09944725558723103, 'num_leaves': 42, 'max_depth': 5, 'min_child_samples': 81, 'subsample': 0.7494241074148139, 'colsample_bytree': 0.6108081327217696}\n",
      "\n",
      "3. Training final model with best parameters...\n",
      "   Final tuned model saved to 'champion_model_lightgbm_tuned.joblib'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def tune_lgbm_model(data_filename=\"model_ready_data.npz\"):\n",
    "    \"\"\"\n",
    "    Finds the best hyperparameters for a LightGBM model using Optuna.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Hyperparameter Tuning for LightGBM ---\")\n",
    "    \n",
    "    # 1. Load Data (we only need train and validation sets for tuning)\n",
    "    print(f\"1. Loading data from '{data_filename}'...\")\n",
    "    with np.load(data_filename, allow_pickle=True) as data:\n",
    "        X_train, y_train = data['X_train'], data['y_train']\n",
    "        X_val, y_val = data['X_val'], data['y_val']\n",
    "\n",
    "    # 2. Define the Objective Function for Optuna\n",
    "    def objective(trial):\n",
    "        \"\"\"The function Optuna tries to minimize.\"\"\"\n",
    "        # Define the search space for hyperparameters\n",
    "        params = {\n",
    "            'objective': 'regression_l1',\n",
    "            'metric': 'mae',\n",
    "            'n_estimators': 1000,\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "            'max_depth': trial.suggest_int('max_depth', -1, 15),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 20, 200),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "            'verbose': -1\n",
    "        }\n",
    "        \n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        \n",
    "        # Train the model with early stopping\n",
    "        model.fit(X_train, y_train,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  eval_metric='mae',\n",
    "                  callbacks=[lgb.early_stopping(50, verbose=False)])\n",
    "        \n",
    "        # Evaluate on the validation set\n",
    "        preds = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, preds)\n",
    "        \n",
    "        return mae\n",
    "\n",
    "    # 3. Run the Optimization Study\n",
    "    print(\"2. Running Optuna study to find best hyperparameters (this will take time)...\")\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=50) # Increase n_trials for a more thorough search\n",
    "\n",
    "    print(\"\\n--- Tuning Complete ---\")\n",
    "    print(f\"Best MAE on validation set: {study.best_value:.4f}\")\n",
    "    print(\"Best hyperparameters found:\")\n",
    "    print(study.best_params)\n",
    "\n",
    "    # 4. Train and Save the Final Tuned Model\n",
    "    print(\"\\n3. Training final model with best parameters...\")\n",
    "    best_params = study.best_params\n",
    "    best_params['objective'] = 'regression_l1'\n",
    "    best_params['random_state'] = 42\n",
    "    \n",
    "    final_model = lgb.LGBMRegressor(**best_params)\n",
    "    \n",
    "    # We train the final model on the combined training and validation data\n",
    "    X_full_train = np.vstack((X_train, X_val))\n",
    "    y_full_train = np.concatenate((y_train, y_val))\n",
    "    \n",
    "    final_model.fit(X_full_train, y_full_train)\n",
    "    \n",
    "    tuned_model_filename = 'champion_model_lightgbm_tuned.joblib'\n",
    "    joblib.dump(final_model, tuned_model_filename)\n",
    "    print(f\"   Final tuned model saved to '{tuned_model_filename}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tune_lgbm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0da2578f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Making a New Prediction ---\n",
      "1. Loading tuned model and data scaler...\n",
      "2. Loading new raw data from 'new_data.csv'...\n",
      "3. Engineering features for the new data point...\n",
      "   Engineered Features:\n",
      "    Feat_RSI  Feat_Close_vs_SMA10  Feat_Close_vs_SMA50  Feat_SMA10_vs_SMA50  \\\n",
      "10       NaN             4.558777                  NaN                  NaN   \n",
      "\n",
      "    Feat_Volume_vs_SMA50  \n",
      "10                   NaN  \n",
      "4. Scaling features using the loaded scaler...\n",
      "5. Making the prediction...\n",
      "\n",
      "--- Prediction Result ---\n",
      "The model predicts a change of: +1.0111% in the next 24 hours.\n",
      "Based on a current price of $42,215.00, the predicted future price is $42,641.82.\n",
      "-------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "def predict_from_new_data(model_path, scaler_path, new_data_path):\n",
    "    \"\"\"\n",
    "    Makes a 24-hour price change prediction from new, raw data.\n",
    "    \"\"\"\n",
    "    print(\"--- Making a New Prediction ---\")\n",
    "\n",
    "    # 1. Load Model and Scaler\n",
    "    print(\"1. Loading tuned model and data scaler...\")\n",
    "    model = joblib.load(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "\n",
    "    # 2. Load and Process New Data\n",
    "    print(f\"2. Loading new raw data from '{new_data_path}'...\")\n",
    "    # For this example, we need some historical context to calculate SMAs\n",
    "    # In a real scenario, you'd pull the last 50+ data points from an API\n",
    "    # Here, we'll just use the last 50 rows of our original data\n",
    "    try:\n",
    "        hist_df = pd.read_csv(\"output_10_rows_processed.csv\").tail(50)\n",
    "        new_df = pd.read_csv(new_data_path)\n",
    "        df = pd.concat([hist_df, new_df], ignore_index=True)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Make sure 'output_10_rows_processed.csv' and 'new_data.csv' are present.\")\n",
    "        return\n",
    "\n",
    "    # 3. Apply EXACTLY the same feature engineering as in prepare_data_v3.py\n",
    "    print(\"3. Engineering features for the new data point...\")\n",
    "    df['SMA_10'] = df['Close'].rolling(window=10).mean()\n",
    "    df['SMA_50'] = df['Close'].rolling(window=50).mean()\n",
    "    df['Volume_SMA_50'] = df['Volume'].rolling(window=50).mean()\n",
    "    \n",
    "    delta = df['Close'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=14).mean()\n",
    "    avg_loss = loss.rolling(window=14).mean()\n",
    "    df['Feat_RSI'] = 100 - (100 / (1 + (avg_gain / avg_loss)))\n",
    "    \n",
    "    df['Feat_Close_vs_SMA10'] = (df['Close'] - df['SMA_10']) / df['SMA_10']\n",
    "    df['Feat_Close_vs_SMA50'] = (df['Close'] - df['SMA_50']) / df['SMA_50']\n",
    "    df['Feat_SMA10_vs_SMA50'] = (df['SMA_10'] - df['SMA_50']) / df['SMA_50']\n",
    "    df['Feat_Volume_vs_SMA50'] = (df['Volume'] - df['Volume_SMA_50']) / df['Volume_SMA_50']\n",
    "\n",
    "    # Isolate the last row, which is our data point to predict\n",
    "    final_features = df[[\n",
    "        'Feat_RSI', 'Feat_Close_vs_SMA10', 'Feat_Close_vs_SMA50', \n",
    "        'Feat_SMA10_vs_SMA50', 'Feat_Volume_vs_SMA50'\n",
    "    ]].tail(1)\n",
    "\n",
    "    print(f\"   Engineered Features:\\n{final_features}\")\n",
    "\n",
    "    # 4. Scale the features\n",
    "    print(\"4. Scaling features using the loaded scaler...\")\n",
    "    scaled_features = scaler.transform(final_features)\n",
    "\n",
    "    # 5. Make Prediction\n",
    "    print(\"5. Making the prediction...\")\n",
    "    prediction = model.predict(scaled_features)\n",
    "    predicted_pct_change = prediction[0]\n",
    "\n",
    "    current_price = df['Close'].iloc[-1]\n",
    "    predicted_future_price = current_price * (1 + predicted_pct_change / 100)\n",
    "\n",
    "    print(\"\\n--- Prediction Result ---\")\n",
    "    print(f\"The model predicts a change of: {predicted_pct_change:+.4f}% in the next 24 hours.\")\n",
    "    print(f\"Based on a current price of ${current_price:,.2f}, the predicted future price is ${predicted_future_price:,.2f}.\")\n",
    "    print(\"-------------------------\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predict_from_new_data(\n",
    "        model_path='champion_model_lightgbm_tuned.joblib',\n",
    "        scaler_path='data_scaler.joblib',\n",
    "        new_data_path='new_data.csv'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae7a6059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Stationary Data Preparation (v3 - with Timestamp) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Parthiva\\AppData\\Local\\Temp\\ipykernel_16656\\954515685.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
      "C:\\Users\\Parthiva\\AppData\\Local\\Temp\\ipykernel_16656\\954515685.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_df.dropna(inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Stationary Data Preparation Complete ---\n",
      "Successfully created 'final_featured_data_v3.csv' with 6681455 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# (This is the same script as before, but with 'Timestamp' added to the final column list)\n",
    "\n",
    "def prepare_stationary_data(raw_input_file=\"btcusd_1-min_data.csv\", \n",
    "                            final_output_file=\"final_featured_data_v3.csv\",\n",
    "                            prediction_horizon_minutes=1440):\n",
    "    print(\"--- Starting Stationary Data Preparation (v3 - with Timestamp) ---\")\n",
    "    \n",
    "    df = pd.read_csv(raw_input_file)\n",
    "\n",
    "    # --- Feature Engineering ---\n",
    "    df['SMA_10'] = df['Close'].rolling(window=10).mean()\n",
    "    df['SMA_50'] = df['Close'].rolling(window=50).mean()\n",
    "    df['Volume_SMA_50'] = df['Volume'].rolling(window=50).mean()\n",
    "\n",
    "    delta = df['Close'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=14).mean()\n",
    "    avg_loss = loss.rolling(window=14).mean()\n",
    "    df['RSI'] = 100 - (100 / (1 + (avg_gain / avg_loss)))\n",
    "\n",
    "    # --- Target Creation ---\n",
    "    future_price = df['Open'].shift(-prediction_horizon_minutes)\n",
    "    df['Target_24h_Pct_Change'] = ((future_price - df['Close']) / df['Close']) * 100\n",
    "\n",
    "    # --- Stationary Feature Creation ---\n",
    "    df['Feat_Close_vs_SMA10'] = (df['Close'] - df['SMA_10']) / df['SMA_10']\n",
    "    df['Feat_Close_vs_SMA50'] = (df['Close'] - df['SMA_50']) / df['SMA_50']\n",
    "    df['Feat_SMA10_vs_SMA50'] = (df['SMA_10'] - df['SMA_50']) / df['SMA_50']\n",
    "    df['Feat_Volume_vs_SMA50'] = (df['Volume'] - df['Volume_SMA_50']) / df['Volume_SMA_50']\n",
    "    df['Feat_RSI'] = df['RSI']\n",
    "\n",
    "    # --- Finalization ---\n",
    "    # **** THIS IS THE KEY CHANGE: WE ARE KEEPING 'Timestamp' ****\n",
    "    final_cols = [\n",
    "        'Timestamp',  # Keep the timestamp\n",
    "        'Target_24h_Pct_Change',\n",
    "        'Feat_RSI',\n",
    "        'Feat_Close_vs_SMA10',\n",
    "        'Feat_Close_vs_SMA50',\n",
    "        'Feat_SMA10_vs_SMA50',\n",
    "        'Feat_Volume_vs_SMA50'\n",
    "    ]\n",
    "    model_df = df[final_cols]\n",
    "\n",
    "    model_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    model_df.dropna(inplace=True)\n",
    "    model_df = model_df.reset_index(drop=True)\n",
    "\n",
    "    model_df.to_csv(final_output_file, index=False)\n",
    "    \n",
    "    print(f\"\\n--- Stationary Data Preparation Complete ---\")\n",
    "    print(f\"Successfully created '{final_output_file}' with {len(model_df)} rows.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    prepare_stationary_data(raw_input_file=\"btcusd_1-min_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4f2dc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Success! Stationary data saved to model_ready_data.npz\n"
     ]
    }
   ],
   "source": [
    "# scale_and_split_data.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def split_and_scale_data(input_filename=\"final_featured_data_v3.csv\", \n",
    "                         output_filename=\"model_ready_data.npz\"):\n",
    "    df = pd.read_csv(input_filename)\n",
    "    y = df['Target_24h_Pct_Change'].values\n",
    "    \n",
    "    # **** KEY CHANGE: DROP TIMESTAMP HERE ****\n",
    "    X = df.drop(columns=['Target_24h_Pct_Change', 'Timestamp']).values\n",
    "\n",
    "    # Rest of the script is the same...\n",
    "    n_total = len(X)\n",
    "    n_train = int(n_total * 0.70)\n",
    "    n_val = int(n_total * 0.15)\n",
    "    \n",
    "    X_train, y_train = X[:n_train], y[:n_train]\n",
    "    X_val, y_val = X[n_train:n_train + n_val], y[n_train:n_train + n_val]\n",
    "    X_test, y_test = X[n_train + n_val:], y[n_train + n_val:]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    np.savez_compressed(output_filename,\n",
    "        X_train=X_train_scaled, y_train=y_train,\n",
    "        X_val=X_val_scaled, y_val=y_val,\n",
    "        X_test=X_test_scaled, y_test=y_test,\n",
    "        scaler=np.array([scaler]))\n",
    "    print(f\"\\nSuccess! Stationary data saved to {output_filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    split_and_scale_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad855752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Strategy Backtest (Corrected v2) ---\n",
      "1. Loading model and test data...\n",
      "2. Merging with original price data...\n",
      "   Successfully merged data. Test set now has 1002219 rows.\n",
      "3. Making predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Simulating trading strategy...\n",
      "5. Calculating final performance metrics...\n",
      "\n",
      "--- Backtest Results ---\n",
      "Initial Portfolio Value: $10,000.00\n",
      "Final Portfolio Value:   $46,401.63\n",
      "Strategy Return:         364.02%\n",
      "Buy and Hold Return:     357.40%\n",
      "------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def backtest(model_path, data_path, npz_path):\n",
    "    print(\"--- Starting Strategy Backtest (Corrected v2) ---\")\n",
    "    \n",
    "    # 1. Load Model and Test Data\n",
    "    print(\"1. Loading model and test data...\")\n",
    "    model = joblib.load(model_path)\n",
    "    \n",
    "    with np.load(npz_path) as data:\n",
    "        X_test_scaled = data['X_test']\n",
    "        \n",
    "    v3_df = pd.read_csv(data_path)\n",
    "    test_start_index = len(v3_df) - len(X_test_scaled)\n",
    "    test_df = v3_df.iloc[test_start_index:].copy()\n",
    "\n",
    "    # --- THIS IS THE ROBUST FIX ---\n",
    "    print(\"2. Merging with original price data...\")\n",
    "    \n",
    "    # **** THIS IS THE CORRECTED LINE ****\n",
    "    # We must use the very first raw file that contains ALL original timestamps.\n",
    "    raw_df = pd.read_csv(\"btcusd_1-min_data.csv\")[['Timestamp', 'Close']] \n",
    "    \n",
    "    test_df = pd.merge(test_df, raw_df, on='Timestamp', how='left')\n",
    "    test_df.rename(columns={'Close': 'Close_Price'}, inplace=True)\n",
    "    test_df.dropna(inplace=True) \n",
    "    \n",
    "    print(f\"   Successfully merged data. Test set now has {len(test_df)} rows.\")\n",
    "    \n",
    "    if len(test_df) == 0:\n",
    "        print(\"   ERROR: Merge resulted in an empty DataFrame. Check if timestamps match.\")\n",
    "        return\n",
    "\n",
    "    # 3. Make Predictions\n",
    "    print(\"3. Making predictions...\")\n",
    "    X_test_scaled = X_test_scaled[:len(test_df)] \n",
    "    predictions = model.predict(X_test_scaled)\n",
    "    test_df['Predicted_Pct_Change'] = predictions\n",
    "\n",
    "    # 4. Simulate the Strategy\n",
    "    print(\"4. Simulating trading strategy...\")\n",
    "    initial_cash = 10000.0\n",
    "    cash = initial_cash\n",
    "    btc_holdings = 0\n",
    "    trade_threshold = 0.5\n",
    "    transaction_fee = 0.001\n",
    "    \n",
    "    portfolio_values = []\n",
    "    \n",
    "    for i in range(len(test_df) - 1):\n",
    "        current_price = test_df['Close_Price'].iloc[i]\n",
    "        \n",
    "        if cash > 0 and test_df['Predicted_Pct_Change'].iloc[i] > trade_threshold:\n",
    "            investment = cash\n",
    "            btc_holdings = (investment * (1 - transaction_fee)) / current_price\n",
    "            cash = 0\n",
    "            \n",
    "        elif btc_holdings > 0 and test_df['Predicted_Pct_Change'].iloc[i] < -trade_threshold:\n",
    "            sale_value = btc_holdings * current_price\n",
    "            cash = sale_value * (1 - transaction_fee)\n",
    "            btc_holdings = 0\n",
    "        \n",
    "        current_portfolio_value = cash + (btc_holdings * current_price)\n",
    "        portfolio_values.append(current_portfolio_value)\n",
    "\n",
    "    # 5. Calculate Final Performance\n",
    "    if not portfolio_values:\n",
    "        print(\"No trades were made, cannot calculate performance.\")\n",
    "        return\n",
    "        \n",
    "    print(\"5. Calculating final performance metrics...\")\n",
    "    final_portfolio_value = portfolio_values[-1]\n",
    "    strategy_return = (final_portfolio_value - initial_cash) / initial_cash * 100\n",
    "\n",
    "    buy_and_hold_start_price = test_df['Close_Price'].iloc[0]\n",
    "    buy_and_hold_end_price = test_df['Close_Price'].iloc[-1]\n",
    "    buy_and_hold_return = (buy_and_hold_end_price - buy_and_hold_start_price) / buy_and_hold_start_price * 100\n",
    "\n",
    "    print(\"\\n--- Backtest Results ---\")\n",
    "    print(f\"Initial Portfolio Value: ${initial_cash:,.2f}\")\n",
    "    print(f\"Final Portfolio Value:   ${final_portfolio_value:,.2f}\")\n",
    "    print(f\"Strategy Return:         {strategy_return:,.2f}%\")\n",
    "    print(f\"Buy and Hold Return:     {buy_and_hold_return:,.2f}%\")\n",
    "    print(\"------------------------\")\n",
    "\n",
    "    # 6. Plot the Results\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(portfolio_values, label='Our Strategy Equity Curve')\n",
    "    buy_and_hold_values = (initial_cash / buy_and_hold_start_price) * test_df['Close_Price']\n",
    "    plt.plot(buy_and_hold_values.values, label=f'Buy and Hold Equity Curve', linestyle='--')\n",
    "    \n",
    "    plt.title('Strategy Performance vs. Buy and Hold')\n",
    "    plt.xlabel('Time (Minutes in Test Period)')\n",
    "    plt.ylabel('Portfolio Value ($)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    backtest(\n",
    "        model_path='champion_model_lightgbm_tuned.joblib',\n",
    "        data_path='final_featured_data_v3.csv',\n",
    "        npz_path='model_ready_data.npz'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1b2b9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n",
      "WeasyPrint could not import some external libraries. Please carefully follow the installation steps before reporting an issue:\n",
      "https://doc.courtbouillon.org/weasyprint/stable/first_steps.html#installation\n",
      "https://doc.courtbouillon.org/weasyprint/stable/first_steps.html#troubleshooting \n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "cannot load library 'libgobject-2.0-0': error 0x7e.  Additionally, ctypes.util.find_library() did not manage to locate a library called 'libgobject-2.0-0'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mweasyprint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTML\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# We will write our report as an HTML string with inline CSS for styling\u001b[39;00m\n\u001b[32m      4\u001b[39m html_content = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[33m<!DOCTYPE html>\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33m<html>\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m \u001b[33m</html>\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\weasyprint\\__init__.py:433\u001b[39m\n\u001b[32m    430\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mstring\u001b[39m\u001b[33m'\u001b[39m, string, base_url, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    432\u001b[39m \u001b[38;5;66;03m# Work around circular imports.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcss\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m preprocess_stylesheet  \u001b[38;5;66;03m# noqa: I001, E402\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhtml\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m    435\u001b[39m     HTML5_UA_COUNTER_STYLE, HTML5_UA_STYLESHEET, HTML5_UA_FORM_STYLESHEET,\n\u001b[32m    436\u001b[39m     HTML5_PH_STYLESHEET)\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Document, Page  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\weasyprint\\css\\__init__.py:28\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01murls\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m URLFetchingError, get_url_attribute, url_join\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m counters, media_queries\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcomputed_values\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m COMPUTER_FUNCTIONS\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mproperties\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m INHERITED, INITIAL_NOT_COMPUTED, INITIAL_VALUES, ZERO_PIXELS\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m preprocess_declarations\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\weasyprint\\css\\computed_values.py:9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtinycss2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolor4\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_color\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LOGGER\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mffi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FROM_UNITS, ffi, pango\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mline_break\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Layout, first_line_metrics\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01murls\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_link_attribute\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\weasyprint\\text\\ffi.py:475\u001b[39m\n\u001b[32m    472\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m suppress((\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m)):\n\u001b[32m    473\u001b[39m             os.add_dll_directory(dll_directory)\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m gobject = \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m    \u001b[49m\u001b[43mffi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlibgobject-2.0-0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgobject-2.0-0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgobject-2.0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlibgobject-2.0.so.0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlibgobject-2.0.dylib\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlibgobject-2.0-0.dll\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m pango = _dlopen(\n\u001b[32m    479\u001b[39m     ffi, \u001b[33m'\u001b[39m\u001b[33mlibpango-1.0-0\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpango-1.0-0\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpango-1.0\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlibpango-1.0.so.0\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    480\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlibpango-1.0.dylib\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlibpango-1.0-0.dll\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    481\u001b[39m harfbuzz = _dlopen(\n\u001b[32m    482\u001b[39m     ffi, \u001b[33m'\u001b[39m\u001b[33mlibharfbuzz-0\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mharfbuzz\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mharfbuzz-0.0\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    483\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlibharfbuzz.so.0\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlibharfbuzz.0.dylib\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlibharfbuzz-0.dll\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\weasyprint\\text\\ffi.py:463\u001b[39m, in \u001b[36m_dlopen\u001b[39m\u001b[34m(ffi, allow_fail, *names)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;66;03m# Re-raise the exception.\u001b[39;00m\n\u001b[32m    454\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    455\u001b[39m     \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-----\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    456\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mWeasyPrint could not import some external libraries. Please \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    461\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfirst_steps.html#troubleshooting\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    462\u001b[39m     \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-----\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mffi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\cffi\\api.py:150\u001b[39m, in \u001b[36mFFI.dlopen\u001b[39m\u001b[34m(self, name, flags)\u001b[39m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdlopen(name): name must be a file name, None, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    148\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mor an already-opened \u001b[39m\u001b[33m'\u001b[39m\u001b[33mvoid *\u001b[39m\u001b[33m'\u001b[39m\u001b[33m handle\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     lib, function_cache = \u001b[43m_make_ffi_library\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m._function_caches.append(function_cache)\n\u001b[32m    152\u001b[39m     \u001b[38;5;28mself\u001b[39m._libraries.append(lib)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\cffi\\api.py:834\u001b[39m, in \u001b[36m_make_ffi_library\u001b[39m\u001b[34m(ffi, libname, flags)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_make_ffi_library\u001b[39m(ffi, libname, flags):\n\u001b[32m    833\u001b[39m     backend = ffi._backend\n\u001b[32m--> \u001b[39m\u001b[32m834\u001b[39m     backendlib = \u001b[43m_load_backend_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlibname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    836\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maccessor_function\u001b[39m(name):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Parthiva\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\cffi\\api.py:829\u001b[39m, in \u001b[36m_load_backend_lib\u001b[39m\u001b[34m(backend, name, flags)\u001b[39m\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m first_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    828\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.  Additionally, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % (first_error, msg)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[32m    830\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m backend.load_library(path, flags)\n",
      "\u001b[31mOSError\u001b[39m: cannot load library 'libgobject-2.0-0': error 0x7e.  Additionally, ctypes.util.find_library() did not manage to locate a library called 'libgobject-2.0-0'"
     ]
    }
   ],
   "source": [
    "from weasyprint import HTML\n",
    "\n",
    "# We will write our report as an HTML string with inline CSS for styling\n",
    "html_content = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Project Report: Bitcoin Price Predictor</title>\n",
    "    <style>\n",
    "        body { font-family: sans-serif; line-height: 1.6; color: #333; }\n",
    "        h1 { color: #1a1a1a; text-align: center; border-bottom: 2px solid #f2a900; padding-bottom: 10px; }\n",
    "        h2 { color: #0d4e87; border-bottom: 1px solid #ccc; padding-bottom: 5px; }\n",
    "        p, ul { margin-bottom: 1em; }\n",
    "        li { margin-left: 20px; }\n",
    "        code { background-color: #f0f0f0; padding: 2px 4px; border-radius: 3px; font-family: monospace; }\n",
    "        .results { background-color: #e8f4fd; border-left: 5px solid #0d4e87; padding: 15px; margin: 20px 0; }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Project Report: Bitcoin Price Predictor</h1>\n",
    "\n",
    "    <h2>Executive Summary</h2>\n",
    "    <p>The primary objective of this project was to develop a machine learning model capable of predicting the price movement of Bitcoin. We successfully built and validated a complete data processing and modeling pipeline, culminating in a strategy that was backtested on unseen historical data.</p>\n",
    "    <p>Our final model, a tuned <b>LightGBM (Light Gradient Boosting Machine)</b>, was trained to predict the <b>percentage price change over the next 24 hours</b>.</p>\n",
    "    <div class=\"results\">\n",
    "        When backtested on the final 15% of our dataset, the model-driven trading strategy achieved a <b>364.02% return</b>, compared to a <b>357.40% return</b> from a simple \"Buy and Hold\" strategy over the same period. This demonstrates that our model possesses a small but significant predictive edge, or <b>alpha</b>, capable of outperforming the market benchmark.\n",
    "    </div>\n",
    "\n",
    "    <h2>The Project Journey: A Tale of Three Attempts</h2>\n",
    "    <p>Our path to a successful model involved overcoming two of the most common pitfalls in financial machine learning:</p>\n",
    "    <ul>\n",
    "        <li><b>Attempt 1: The Data Leakage Pitfall</b> - We initially tried to predict the price moments into the future, which resulted in a useless model that only copied the last known price.</li>\n",
    "        <li><b>Attempt 2: The Persistence Model Pitfall</b> - We then predicted the absolute price 24 hours ahead. This was also flawed, as the model learned the lazy rule that the future price is similar to the current price.</li>\n",
    "        <li><b>Attempt 3: The Correct Approach (Stationarity)</b> - We finally succeeded by reformulating the problem: predict the <i>percentage change</i> using <i>relative features</i>. This forced the model to learn true market dynamics.</li>\n",
    "    </ul>\n",
    "\n",
    "    <h2>The Backtesting Strategy Explained</h2>\n",
    "    <p>Backtesting is a simulation of how our model would have performed historically. Our strategy was:</p>\n",
    "    <ul>\n",
    "        <li><b>The Signal:</b> Use the model's 24-hour percentage change prediction.</li>\n",
    "        <li><b>Confidence Threshold:</b> Only trade if the predicted move (up or down) was greater than <b>0.5%</b>. This filters out noise and reduces unnecessary trades.</li>\n",
    "        <li><b>Realistic Costs:</b> A transaction fee of <b>0.1%</b> was applied to every trade.</li>\n",
    "    </ul>\n",
    "\n",
    "    <h2>Final Backtest Results & Conclusion</h2>\n",
    "    <div class=\"results\">\n",
    "        <ul>\n",
    "            <li>Initial Portfolio Value: <b>$10,000.00</b></li>\n",
    "            <li>Final Portfolio Value: <b>$46,401.63</b></li>\n",
    "            <li>Strategy Return: <b>364.02%</b></li>\n",
    "            <li>Buy and Hold Return: <b>357.40%</b></li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <p>Our strategy successfully generated <b>alpha (excess return) of 6.62%</b> over the market benchmark. This proves that the features we engineered contain real predictive information and that our LightGBM model learned to exploit it effectively, even after accounting for transaction costs. We have successfully built a system with a small but demonstrable statistical edge.</p>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# --- Generate the PDF ---\n",
    "output_filename = \"Styled_Bitcoin_Report.pdf\"\n",
    "HTML(string=html_content).write_pdf(output_filename)\n",
    "\n",
    "print(f\"Success! Styled report saved as '{output_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c9df49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Report saved as 'Bitcoin_Predictor_Report.pdf'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Parthiva\\AppData\\Local\\Temp\\ipykernel_16656\\112132605.py:5: DeprecationWarning: Substituting font arial by core font helvetica - This is deprecated since v2.7.8, and will soon be removed\n",
      "  self.set_font('Arial', 'B', 12)\n",
      "C:\\Users\\Parthiva\\AppData\\Local\\Temp\\ipykernel_16656\\112132605.py:6: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=1 use new_x=XPos.LMARGIN, new_y=YPos.NEXT.\n",
      "  self.cell(0, 10, 'Project Report: Bitcoin Price Predictor', 0, 1, 'C')\n",
      "C:\\Users\\Parthiva\\AppData\\Local\\Temp\\ipykernel_16656\\112132605.py:15: DeprecationWarning: Substituting font arial by core font helvetica - This is deprecated since v2.7.8, and will soon be removed\n",
      "  self.set_font('Arial', 'B', 12)\n",
      "C:\\Users\\Parthiva\\AppData\\Local\\Temp\\ipykernel_16656\\112132605.py:16: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=1 use new_x=XPos.LMARGIN, new_y=YPos.NEXT.\n",
      "  self.cell(0, 10, title, 0, 1, 'L')\n",
      "C:\\Users\\Parthiva\\AppData\\Local\\Temp\\ipykernel_16656\\112132605.py:20: DeprecationWarning: Substituting font arial by core font helvetica - This is deprecated since v2.7.8, and will soon be removed\n",
      "  self.set_font('Arial', '', 11)\n",
      "C:\\Users\\Parthiva\\AppData\\Local\\Temp\\ipykernel_16656\\112132605.py:11: DeprecationWarning: Substituting font arial by core font helvetica - This is deprecated since v2.7.8, and will soon be removed\n",
      "  self.set_font('Arial', 'I', 8)\n",
      "C:\\Users\\Parthiva\\AppData\\Local\\Temp\\ipykernel_16656\\112132605.py:12: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=0 use new_x=XPos.RIGHT, new_y=YPos.TOP.\n",
      "  self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')\n"
     ]
    }
   ],
   "source": [
    "from fpdf import FPDF\n",
    "\n",
    "class PDF(FPDF):\n",
    "    def header(self):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, 'Project Report: Bitcoin Price Predictor', 0, 1, 'C')\n",
    "        self.ln(5)\n",
    "\n",
    "    def footer(self):\n",
    "        self.set_y(-15)\n",
    "        self.set_font('Arial', 'I', 8)\n",
    "        self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')\n",
    "\n",
    "    def chapter_title(self, title):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, title, 0, 1, 'L')\n",
    "        self.ln(2)\n",
    "\n",
    "    def chapter_body(self, body_text):\n",
    "        self.set_font('Arial', '', 11)\n",
    "        self.multi_cell(0, 5, body_text)\n",
    "        self.ln()\n",
    "\n",
    "# --- The Content of Our Report ---\n",
    "report_content = {\n",
    "    \"Executive Summary\": \"\"\"The primary objective of this project was to develop a machine learning model capable of predicting the price movement of Bitcoin. We successfully built and validated a complete data processing and modeling pipeline, culminating in a strategy that was backtested on unseen historical data.\n",
    "\n",
    "Our final model, a tuned LightGBM (Light Gradient Boosting Machine), was trained to predict the percentage price change over the next 24 hours.\n",
    "\n",
    "When backtested on the final 15% of our dataset, the model-driven trading strategy achieved a 364.02% return, compared to a 357.40% return from a simple \"Buy and Hold\" strategy over the same period. This demonstrates that our model, while not a perfect crystal ball, possesses a small but significant predictive edge, or alpha, capable of outperforming the market benchmark.\"\"\",\n",
    "\n",
    "    \"The Project Journey: A Tale of Three Attempts\": \"\"\"Our path to a successful model was not linear. It involved overcoming two of the most common and dangerous pitfalls in financial machine learning, which highlights the importance of a rigorous methodology.\n",
    "\n",
    "Attempt 1: The Data Leakage Pitfall\n",
    "- Initial Goal: Predict the Next_Day_Open.\n",
    "- The Problem: We used data from the last minute of a day to predict the price moments later.\n",
    "- The Flawed Result: The model appeared incredibly accurate (99%+ R-squared), but it was only learning to copy the last known price, a useless \"prediction.\"\n",
    "\n",
    "Attempt 2: The Persistence Model Pitfall\n",
    "- Second Goal: Predict the absolute price 24 hours in the future.\n",
    "- The Problem: The model still appeared highly accurate because the price in 24 hours is strongly correlated with the price now.\n",
    "- The Flawed Result: A simple linear model won again by learning the lazy rule: Future_Price is approximately equal to Current_Price.\n",
    "\n",
    "Attempt 3: The Correct Approach (Stationarity)\n",
    "- Final Goal: Predict the *percentage change* in price over the next 24 hours.\n",
    "- The Solution: We transformed both our features and our target to be relative (e.g., price vs. moving average). This forced the model to learn market *dynamics*, not just copy the current state. This produced a realistic and useful model.\"\"\",\n",
    "\n",
    "    \"The Backtesting Strategy Explained\": \"\"\"Backtesting is a simulation of how our model would have performed historically. Our strategy was designed to be simple and realistic.\n",
    "\n",
    "- The Signal: At every minute, our model provides a prediction for the percentage change over the next 24 hours.\n",
    "- Buy Condition: If we are holding cash AND the model predicts a price increase of more than 0.5%, we invest 100% of our cash into Bitcoin.\n",
    "- Sell Condition: If we are holding Bitcoin AND the model predicts a price decrease of more than 0.5%, we sell 100% of our holdings back to cash.\n",
    "- Confidence Threshold: The 0.5% rule is crucial. It filters out low-conviction signals and prevents over-trading, which would otherwise be eaten up by fees.\n",
    "- Transaction Fee: We applied a realistic 0.1% fee to every single buy and sell trade.\"\"\",\n",
    "\n",
    "    \"Final Backtest Results & Conclusion\": \"\"\"- Initial Portfolio Value: $10,000.00\n",
    "- Final Portfolio Value:   $46,401.63\n",
    "- Strategy Return:         364.02%\n",
    "- Buy and Hold Return:     357.40%\n",
    "\n",
    "Our strategy successfully generated alpha (excess return) of 6.62% over the market benchmark. This proves that the features we engineered contain real predictive information and that our LightGBM model learned to exploit it effectively, even after accounting for transaction costs. We have successfully built a system with a small but demonstrable statistical edge.\"\"\"\n",
    "}\n",
    "\n",
    "# --- Generate the PDF ---\n",
    "pdf = PDF()\n",
    "pdf.add_page()\n",
    "\n",
    "for title, body in report_content.items():\n",
    "    pdf.chapter_title(title)\n",
    "    pdf.chapter_body(body)\n",
    "\n",
    "output_filename = \"Bitcoin_Predictor_Report.pdf\"\n",
    "pdf.output(output_filename)\n",
    "\n",
    "print(f\"Success! Report saved as '{output_filename}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
